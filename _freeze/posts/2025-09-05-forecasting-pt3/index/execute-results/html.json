{
  "hash": "d8e4a72ed4121e6b3b571a7fad595487",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"index\"\nformat: html\n---\n\n---\ntitle:\n \"Harnessing CHC-CMIP6 Climate Scenario Data to Explore the Future\"\ndescription: |\n Returning to our series on future estimation, we provide an overview of a data source for future climate scenarios.\nauthor:\n  - name: Rebecca Luttinen\n    affiliation: IPUMS Global Health Data Analyst\n  - name: Jessie Pinchoff\n    affiliation: IPUMS Researcher\ndate: 09-05-2025\nimage: images/clipboard-1796866763.png\ncategories:\n  - Climate\n  - Scenarios\n  - Temperature\n  - R\n  - CHIRTS\n  - Comparison\n  - GGSPATIAL\n  - Terra\n  - SF\nfig-width: 10\nfig-height: 8\nbibliography: references.bib\nopen-graph:\n  title: |\n     Harnessing CHC-CMIP6 Climate Scenario Data to Explore the Future\n  description: |\n    Returning to our series on future estimation, we provide an overview of a data source for future climate scenarios.\n  twitter-card:\n  title: |\n    Harnessing CHC-CMIP6 Climate Scenario Data to Explore the Future\n  description: |\n     Returning to our series on future estimation, we provide an overview of a data source for future climate scenarios.\nimage: images/clipboard-1796866763.png\n---\n\n\n\nWe now return to our series on using methods of future estimation in spatial health research. The third post in this series introduces [CHC-CMIP6 data](https://www.chc.ucsb.edu/data/chc-cmip6) by the Climate Hazards Center at UC Santa Barbara. We will demonstrate how you can read these data into R to create informative visualizations.  Kenya will be our example context, continuing from our [previous post](https://tech.popdata.org/dhs-research-hub/posts/2025-06-03-forecasting-pt2/) in this series\n\n# **Long-term Climate Projections**\n\nNow that we’ve shown how we can use forecasts, predictions and scenarios to explore future demographic and health patterns, how does climate change fit in?\n\nWe discussed [Subseasonal to seasonal (S2S) forecasts](https://www.sciencedirect.com/science/article/abs/pii/S0022169421011082) earlier in this series, which extend short-term weather forecasts from two weeks to two years into the future. Climate change patterns, however, may shift over many years, and often, climate researchers are predicting much further into the future. These predictions can assist policymakers in thinking about how what they do today may impact the future.\n\nThe Intergovernmental Panel on Climate Change (IPCC) is the UN agency that studies climate change, and its annual Conference of Parties (COP) meetings bring together experts in climate change, agriculture, demography, health and other fields to help governments make pledges to increase resources to address climate change. IPCC synthesizes global climate research into comprehensive, authoritative IPCC reports that represent the scientific consensus on climate change, its impacts, and how human activities affect greenhouse gas emissions, providing the foundation for climate policy decisions.\n\nTo understand how climate change may shift in the long-term, the IPCC and researchers around the world use the Shared Socioeconomic Pathways (SSPs) to understand our possible future worlds. For example, SSP 5-8.5 assumes a world where we fail to cut emissions or switch to clean energy, the population grows, and emissions increase rapidly. SSP 2-4.5 is considered the “middle of the road” scenario, a future where greenhouse gas emissions hover around current levels and perhaps start declining but don’t reach net-zero by 2100. The SSP’s consider challenges to mitigation (bringing down emissions) and adaptation (taking steps to reduce exposure and harm). Using the SSPs, scientists can explore how climate and demographic patterns will shift under each possible future scenario.\n\nThe figure below summarizes each single SSP, which is considered the starting point. Read more at the link below the figure to understand the different kinds of assumptions applied to each SSP (i.e. the-4.5 in SSP 2-4.5).\n\n::: colum-body.outset\n![](images/clipboard-1796866763.png)\n\n*Figure: The five SSPs and the associated challenges to mitigation and adaptation.* ([*https://climatedata.ca/resource/understanding-shared-socio-economic-pathways-ssps/*](https://climatedata.ca/resource/understanding-shared-socio-economic-pathways-ssps/)*)*\n:::\n\n# The Couple Model Intercomparison Project Phase 6 (CMIP-6)\n\nThe Coupled Model Intercomparison Project Phase 6 (CMIP6) is a global collaboration among climate modeling centers. CMIP6 simulates the earth’s climate system, including the atmosphere, oceans and land surface, across each SSP. Each model starts by running historical data from the past 100-150 years, to see if they can reproduce past climate trends. Then, they feed the model different possible futures through the SSPs. Lastly, the models simulate the future climate, often up to the year 2100 or even 2300, and simulate how temperatures may rise, rainfall patterns may change, or extreme events may increase. Because many research teams around the world are running these models independently, CMIP6 can explore dozens of different models using the same standardized scenarios for comparability.\n\nOnce the simulations are done, scientists can compare the models, average the results, and assess uncertainty levels. The final CMIP6-informed climate projections can be used to guide IPCC reports and guidance, as well as country level national determined contributions (NDCs), adaptation plans, and risk assessments, to guide policy decisions on the ground. To be useful at this level, we need spatially and temporally detailed datasets, that downscale the full model down to more localized estimates and patterns.\n\n::: callout-note\n# **What is downscaling?**\n\nCMIP6 projections are global, and for use at the national or subnational level are often too coarse.  Downscaling methods can be used to create finer, more locally relevant climate information to capture regional trends and be useful for more local policy. Downscaling can be done using statistical methods (such as bias correction and spatial disaggregation) or dynamic approaches (such as regional climate models). The result is a high-resolution climate projection that can be used by researchers and policymakers.\n\nCHC researchers downscaled the CMIP6 from global to more local levels, if you are interested in their methodology please read this [paper](https://www.nature.com/articles/s41597-024-03074-w).\n:::\n\n::: column-margin\nWe will be using a dataset created by researchers at the Climate Hazards Center (CHC). We used observed climate data from CHC in these earlier posts: 1) [Flexible Workflows with CHIRTS Temperature Data](https://tech.popdata.org/dhs-research-hub/posts/2024-04-15-chirts-metrics/) and 2) [Attaching CHIRPS Precipitation Data to DHS Surveys.](https://tech.popdata.org/dhs-research-hub/posts/2024-02-04-dhs-chirps/) The format of the projected data is the same as the historical data. This is because the projected data is calculated by adding a daily delta to observed historical data, which is the amount of 'change' a climate value is expected to experience.\n:::\n\n# CHC-CMIP6 Datasets\n\nThe Climate Hazards Center uses CMIP6 outputs and tailors them for more applied research needs. They recently downscaled CMIP6 climate projections to produce high-resolution, bias-corrected datasets that are more useful for local applications. They produced daily 0.05ᵒ gridded data of the Climate Hazards InfraRed Temperature with Stations (CHIRTS) temperature product. So far, CHIRTS has been a historical dataset with daily maximum temperature estimates from 1981-2024, but now we can explore future temperature estimates for 2030 and 2050.\n\n::: column-margin\nWe can use CHC-CMIP data to predict child health outcomes. As this blog has demonstrated, the Demographic and Health Surveys have important, nationally representative information on child health and well-being from countries that often lack detailed health metrics. The DHS includes GPS coordinates for communities where households are sampled, and this information can then be used to link with CHC-CMIP6 downscaled projections by location. We will explore this in our next post in this series.\n:::\n\n# How to Access and Read the Scenario Data into R\n\nFor this exercise we will work with temperature data for one month, January, which is during the hot season in Kenya for each scenario and time-frame. If you're interested in working with rainfall data, you can adapt this code, using the previous CHIRPS post (see above) to download projected rainfall data.\n\n::: callout-note\nYou can find the Tmax files for 2030 for 2-4.5 [here](https://data.chc.ucsb.edu/products/CHC_CMIP6/2030_SSP245/Tmax/) and 5-8.5 [here](https://data.chc.ucsb.edu/products/CHC_CMIP6/2030_SSP585/Tmax/). You can find the Tmax files for 2050 for 2-4.5 [here](https://data.chc.ucsb.edu/products/CHC_CMIP6/2050_SSP245/Tmax/) and 5-8.5 [here](https://data.chc.ucsb.edu/products/CHC_CMIP6/2050_SSP585/Tmax/2016/). **Note**: *both the projections for 2030 and 2050 come from the files labeled for the year of 2016. As we mentioned earlier, the projection data is calculated by adding a daily delta to each observation.*\n:::\n\nOnce those files are downloaded we will create a file path to .tif files.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create list of paths to all individual raster files\n\nprojections_files_245_2030<- list.files(\"data/SSP_245_2030_Tmax\", full.names = TRUE)\n\nprojections_files_585_2030<- list.files(\"data/SSP_585_2030_Tmax\", full.names = TRUE)\n\nprojections_files_245_2050<- list.files(\"data/SSP_245_2050_Tmax\", full.names = TRUE)\n\nprojections_files_585_2050<- list.files(\"data/SSP_585_2050_Tmax\", full.names = TRUE)\n\n```\n:::\n\n\n\nThen we will load the files as multiple layers in a raster stack, similar to the workflow demonstrated in this [earlier post](https://tech.popdata.org/dhs-research-hub/posts/2024-02-04-dhs-chirps/) on how to use precipitation data from the Climate Hazards Center.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(terra)\n\n# Load each set of .tif files into into its own single raster stack\n\nproj_temp_raster_245_2030 <- rast(projections_files_245_2030)\n\nproj_temp_raster_585_2030 <- rast(projections_files_585_2030)\n\nproj_temp_raster_245_2050 <- rast(projections_files_245_2050)\n\nproj_temp_raster_585_2050 <- rast(projections_files_585_2050)\n\n```\n:::\n\n\n\nThe scenario data is provided at the global level, so first we must crop this raster to only cover Kenya. We can do this by using a shapefile for Kenya available on from the [Humanitarian Data Exchange](https://data.humdata.org/), which also has county-level geocodes. First, we read in this shapefile.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\n\n#read in Kenya ADM1 shapefiles\n\nken_ADM1_borders <- st_read(\n  \"data/geoBoundaries-KEN-ADM1-all/geoBoundaries-KEN-ADM1.shp\",\n  quiet = TRUE)\n\n#make sure the projection systems for our shapefiles and our raster data match\n\ncrs(ken_ADM1_borders)\n#> [1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2296)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n\ncrs(proj_temp_raster_245_2030)\n#> [1] \"GEOGCRS[\\\"WGS 84\\\",\\n    ENSEMBLE[\\\"World Geodetic System 1984 ensemble\\\",\\n        MEMBER[\\\"World Geodetic System 1984 (Transit)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G730)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G873)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1150)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1674)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G1762)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2139)\\\"],\\n        MEMBER[\\\"World Geodetic System 1984 (G2296)\\\"],\\n        ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        ENSEMBLEACCURACY[2.0]],\\n    PRIMEM[\\\"Greenwich\\\",0,\\n        ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    CS[ellipsoidal,2],\\n        AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n            ORDER[1],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n            ORDER[2],\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n    USAGE[\\n        SCOPE[\\\"Horizontal component of 3D system.\\\"],\\n        AREA[\\\"World.\\\"],\\n        BBOX[-90,-180,90,180]],\\n    ID[\\\"EPSG\\\",4326]]\"\n```\n:::\n\n\n\nThen we crop each raster according to the boundaries of the said shapefile.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#crop each raster so we only have the Tmax information for Kenya\n\n#2-4.5-2030\n\nken_Tmax_245_2030<- crop(proj_temp_raster_245_2030, ken_ADM1_borders, snap = \"out\")\n\n#5-8.5- 2030\n\nken_Tmax_585_2030<- crop(proj_temp_raster_585_2030, ken_ADM1_borders, snap = \"out\")\n\n#2-4.5-2050\n\nken_Tmax_245_2050<- crop(proj_temp_raster_245_2050, ken_ADM1_borders, snap = \"out\")\n\n#5-8.5- 2050\n\nken_Tmax_585_2050<- crop(proj_temp_raster_585_2050, ken_ADM1_borders, snap = \"out\")\n\n```\n:::\n\n\n\nNow we have cropped our data scenario data to Kenya. If we enter the name of one of the cropped objects we have created you can see the max temperature is 44.85 degrees Celsius.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nken_Tmax_245_2030\n#> class       : SpatRaster \n#> dimensions  : 204, 161, 31  (nrow, ncol, nlyr)\n#> resolution  : 0.05, 0.05  (x, y)\n#> extent      : 33.9, 41.95, -4.750001, 5.449999  (xmin, xmax, ymin, ymax)\n#> coord. ref. : lon/lat WGS 84 (EPSG:4326) \n#> source(s)   : memory\n#> names       : 2030_~01.01, 2030_~01.02, 2030_~01.03, 2030_~01.04, 2030_~01.05, 2030_~01.06, ... \n#> min values  : -9999.00000, -9999.00000, -9999.00000, -9999.00000, -9999.00000, -9999.00000, ... \n#> max values  :    44.42629,    42.74142,    43.23469,    41.90297,    41.62671,    43.20387, ...\n```\n:::\n\n\n\nOur minimum value is listed at -9999, indicating missing information. We will need to drop these values by labeling any negative values as NA's.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set pixels with a value less than 0 to NA\n  \nken_Tmax_245_2030[ken_Tmax_245_2030 < 0] <- NA\n\nken_Tmax_245_2050[ken_Tmax_245_2050 < 0] <- NA\n\nken_Tmax_585_2030[ken_Tmax_585_2030 < 0] <- NA\n\nken_Tmax_585_2050[ken_Tmax_585_2050 < 0] <- NA\n```\n:::\n\n\n\n# How to Temporally Aggregate the Data\n\nNow we must temporally aggregate our data. First we will manually add date information to our data since the metadata does not include date information. See how we get NA's when we use the following code.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntime(ken_Tmax_245_2030)\n#>  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n#> [26] NA NA NA NA NA NA\n```\n:::\n\n\n\nFortunately, the original .tif files are labeled by their date, so we can manually input the date information using the following code.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\n#temporally aggregate the scenario data\n\nlibrary(lubridate)\n#> \n#> Attaching package: 'lubridate'\n#> The following objects are masked from 'package:terra':\n#> \n#>     intersect, union\n#> The following objects are masked from 'package:base':\n#> \n#>     date, intersect, setdiff, union\n\n# Convert strings to Date objects for the 2030 and 2050 timeframes\n\nstart2030 <- lubridate::ymd(\"2030-01-01\")\nend2030 <- lubridate::ymd(\"2030-1-31\")\n\nstart2050 <- lubridate::ymd(\"2050-01-01\")\nend2050 <- lubridate::ymd(\"2050-1-31\")\n\n# Set time as a daily sequence of the month of January\n\n#2-4.5:2030\ntime(ken_Tmax_245_2030) <- seq(start2030, end2030, by = \"days\")\n\n#5-8.5: 2030\n\ntime(ken_Tmax_585_2030) <- seq(start2030, end2030, by = \"days\")\n\n#2-4.5:2050\ntime(ken_Tmax_245_2050) <- seq(start2050, end2050, by = \"days\")\n\n#5-8.5: 2050\n\ntime(ken_Tmax_585_2050) <- seq(start2050, end2050, by = \"days\")\n```\n:::\n\n\n\nNow we can confirm if the code works.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntime(ken_Tmax_245_2030)\n#>  [1] \"2030-01-01\" \"2030-01-02\" \"2030-01-03\" \"2030-01-04\" \"2030-01-05\"\n#>  [6] \"2030-01-06\" \"2030-01-07\" \"2030-01-08\" \"2030-01-09\" \"2030-01-10\"\n#> [11] \"2030-01-11\" \"2030-01-12\" \"2030-01-13\" \"2030-01-14\" \"2030-01-15\"\n#> [16] \"2030-01-16\" \"2030-01-17\" \"2030-01-18\" \"2030-01-19\" \"2030-01-20\"\n#> [21] \"2030-01-21\" \"2030-01-22\" \"2030-01-23\" \"2030-01-24\" \"2030-01-25\"\n#> [26] \"2030-01-26\" \"2030-01-27\" \"2030-01-28\" \"2030-01-29\" \"2030-01-30\"\n#> [31] \"2030-01-31\"\n```\n:::\n\n\n\nNow that we know we have temporal information, we aggregate our data to the monthly level. In this example we will pull the monthly averages.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#aggregate into monthly averages\n\n#2-4.5:2030\n\nken_Tmax_245_2030_yearmonth<-tapp(ken_Tmax_245_2030, fun=mean, index=\"yearmonth\")\n\n#5-8.5:2030\n\nken_Tmax_585_2030_yearmonth<-tapp(ken_Tmax_585_2030, fun=mean, index=\"yearmonth\")\n\n#2-4.5:2050\n\nken_Tmax_245_2050_yearmonth<-tapp(ken_Tmax_245_2050, fun=mean, index=\"yearmonth\")\n\n#5-8.5:2050\n\nken_Tmax_585_2050_yearmonth<-tapp(ken_Tmax_585_2050, fun=mean, index=\"yearmonth\")\n```\n:::\n\n\n\n# Aggregate to the Spatial Level\n\nNow that our data is temporally aggregated, we must aggregate it at the spatial level. Like we have used a [DHS cluster buffer zone](https://tech.popdata.org/dhs-research-hub/posts/2024-02-04-dhs-chirps/#cluster-buffers) in the past, now we will transform Demographic and Health Survey (DHS) cluster GPS information into a 10-kilometer buffer zone. We use the same survey as the last post in this series: Kenya 2022.\n\nFirst, we read in our DHS GPS data, which you can access on the DHS [website](https://dhsprogram.com/).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nken_DHS_gps<-st_read(\"data/DHS_clusters/KEGE8AFL.shp\")\n#> Reading layer `KEGE8AFL' from data source \n#>   `C:\\Users\\Rebecca\\Documents\\Projects\\dhs-research-hub\\posts\\2025-09-05-forecasting-pt3\\data\\DHS_clusters\\KEGE8AFL.shp' \n#>   using driver `ESRI Shapefile'\n#> Simple feature collection with 1691 features and 20 fields\n#> Geometry type: POINT\n#> Dimension:     XY\n#> Bounding box:  xmin: 33.96339 ymin: -4.633603 xmax: 41.87537 ymax: 4.930862\n#> Geodetic CRS:  WGS 84\n```\n:::\n\n\n\nNext, we transform this into a 10-kilometer buffer zone. We use the [UTM 37N reference](https://epsg.io/?q=Kenya%20%20kind%3ACRS#google_vignette) system because it is best for Kenya.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Project cluster locations to the UTM 37N reference system\n\nken_DHS_gps <- st_transform(ken_DHS_gps, crs = 21097)\n\n#create buffer zone\n\nken_DHS_buffer <- st_buffer(ken_DHS_gps, dist = 10000)\n\n#transform it back to ESPG 4326 for degrees of longitude and latitude\n\nken_DHS_buffer <- st_transform(ken_DHS_gps, crs = 4326)\n```\n:::\n\n\n\nNow we will use the extract() function from the terra package to get spatial mean of the Tmax per DHS cluster buffer zone.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n#2-4.5:2030\n\nken_Tmax_245_2030_spatial_mean <- terra::extract(\n  ken_Tmax_245_2030_yearmonth, # Extract values for each month \n  ken_DHS_buffer,      # Use Kenya 2022 DHS buffer zone\n  weights = TRUE,\n  fun = \"mean\",         #get the spatial mean\n  na.rm = TRUE,\n  bind=TRUE)\n\n#convert to a spatial frame\nken_Tmax_245_2030_spatial_mean_sf<-st_as_sf(ken_Tmax_245_2030_spatial_mean)\n\n#5-8.5:2030\n\nken_Tmax_585_2030_spatial_mean <- terra::extract(\n  ken_Tmax_585_2030_yearmonth, # Extract values for each month \n  ken_DHS_buffer,      # Use Kenya 2022 DHS buffer zone\n  weights = TRUE,\n  fun = \"mean\",           #get the spatial mean\n  na.rm = TRUE,\n  bind=TRUE)\n\n#convert to a spatial frame\nken_Tmax_585_2030_spatial_mean_sf<-st_as_sf(ken_Tmax_585_2030_spatial_mean)\n\n#2-4.5:2050\n\nken_Tmax_245_2050_spatial_mean <- terra::extract(\n  ken_Tmax_245_2050_yearmonth, # Extract values for each month \n  ken_DHS_buffer,      # Use Kenya 2022 DHS buffer zone\n  weights = TRUE,\n  fun = \"mean\",           #get the spatial mean\n  na.rm = TRUE,\n  bind=TRUE)\n\n#convert to a spatial frame\nken_Tmax_245_2050_spatial_mean_sf<-st_as_sf(ken_Tmax_245_2050_spatial_mean)\n\n#5-8.5:2050\n\nken_Tmax_585_2050_spatial_mean <- terra::extract(\n  ken_Tmax_585_2050_yearmonth, # Extract values for each month \n  ken_DHS_buffer,      # Use Kenya 2022 DHS cluster GPS file\n  weights = TRUE,\n  fun = \"mean\",           #get the spatial mean\n  na.rm = TRUE,\n  bind=TRUE)\n\n#convert to a spatial frame\nken_Tmax_585_2050_spatial_mean_sf<-st_as_sf(ken_Tmax_585_2050_spatial_mean)\n\n```\n:::\n\n\n\n# Visualization Demo\n\nNow, let's visualize the scenario data using both maps and graphics. From the above code, we have generated four different vectors of data: one for each scenario in 2030 and 2050. Next we will do some basic recoding and reformatting to ensure our variables are properly labeled before we merge the vectors, which we will need to do in order to visualize these differences on one graph.\n\nFirst, we will convert our spatial frames, which we created above, to dataframe. Then we will label our temporal data based on which SSP it came from.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n#recodes\n\nlibrary(tidyverse)\n\n#2-4.5:2030\nken_Tmax_245_2030_spatial_mean_df <- as.data.frame(ken_Tmax_245_2030_spatial_mean)\n\nken_Tmax_245_2030_spatial_mean_df<-ken_Tmax_245_2030_spatial_mean_df%>%\n  rename(ym_203001_245=ym_203001)\n\n#5-8.5:2030\n\nken_Tmax_585_2030_spatial_mean_df <- as.data.frame(ken_Tmax_585_2030_spatial_mean)\n\nken_Tmax_585_2030_spatial_mean_df<-ken_Tmax_585_2030_spatial_mean_df%>%\n  rename(ym_203001_585=ym_203001)\n\n#2-4.5:2050\nken_Tmax_245_2050_spatial_mean_df <- as.data.frame(ken_Tmax_245_2050_spatial_mean)\n\nken_Tmax_245_2050_spatial_mean_df<-ken_Tmax_245_2050_spatial_mean_df%>%\n  rename(ym_205001_245=ym_205001)\n\n#5-8.5:2050\n\nken_Tmax_585_2050_spatial_mean_df <- as.data.frame(ken_Tmax_585_2050_spatial_mean)\n\nken_Tmax_585_2050_spatial_mean_df<-ken_Tmax_585_2050_spatial_mean_df%>%\n  rename(ym_205001_585=ym_205001)\n \n```\n:::\n\n\n\nNow that our data is labeled based on which SSP it came from, we combine all of the scenario data into one dataframe. If we were to skip the step in which we labeled the temporal data per SSP, we could mix up the 2030 and 2050 data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#merge frames\n\ncombined_SSPs_2030<-left_join(ken_Tmax_245_2030_spatial_mean_df, ken_Tmax_585_2030_spatial_mean_df)\n\ncombined_SSPs_2050<-left_join(ken_Tmax_245_2050_spatial_mean_df, ken_Tmax_585_2050_spatial_mean_df)\n\ncombined_SSP_all<-left_join(combined_SSPs_2030, combined_SSPs_2050)\n```\n:::\n\n\n\nAfter merging the data together, we will reshape the data to a long format, so our data is at the year-month level and is disaggregated per scenario. This means we have four observations, or rows, per DHS cluster.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#pivot the dataframe to make date long\n\ncombined_SSPs_long <- combined_SSP_all %>%\n  pivot_longer(\n    cols = contains (\"ym_\"),     # specify the date columns as what need to be pivoted\n    names_to = \"Date\",        # new column for date\n    values_to = \"Tmax\"           # new column for Tmax\n  )\n\n#print dataframe to illustrate the structure\ncombined_SSPs_long%>%\n  select(DHSCLUST, Tmax, Date)%>%\n  head(n=12)\n#> # A tibble: 12 × 3\n#>    DHSCLUST  Tmax Date         \n#>       <dbl> <dbl> <chr>        \n#>  1        1  37.0 ym_203001_245\n#>  2        1  37.0 ym_203001_585\n#>  3        1  37.4 ym_205001_245\n#>  4        1  37.7 ym_205001_585\n#>  5        2  36.9 ym_203001_245\n#>  6        2  37.0 ym_203001_585\n#>  7        2  37.4 ym_205001_245\n#>  8        2  37.6 ym_205001_585\n#>  9        3  36.9 ym_203001_245\n#> 10        3  37.0 ym_203001_585\n#> 11        3  37.4 ym_205001_245\n#> 12        3  37.7 ym_205001_585\n```\n:::\n\n\n\nFollowing the reshaping, we will create a variable to differentiate which scenario the data comes from: 2-4.5 or 5-8.5. Then we will recode the date to remove the SSP labels that we added to the end.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#create a dichotomous variable for each scenario\n\ncombined_SSPs_long <- combined_SSPs_long %>%\n  mutate(SSP = case_when(\n    str_detect(Date, \"585\") ~ \"585\",\n    str_detect(Date, \"245\") ~ \"245\"\n  ))\n\n#recode date\n\ncombined_SSPs_long <- combined_SSPs_long %>%\n  mutate(year_month = str_extract(Date, \"\\\\d{6}\"))%>%\n  mutate(year_month = str_replace(str_extract(year_month, \"\\\\d{6}\"), \"(\\\\d{4})(\\\\d{2})\", \"\\\\1-\\\\2\"))\n\n```\n:::\n\n\n\nIn order to create a summary visualization, we need to make some trade-offs. There are 1692 different DHS clusters. In this example, we select the first five DHS cluster buffer zones, and create a line graph showing the differences in the projected Tmax for 2030 and 2050 per SSP.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\n#select the first 5 DHS cluster locations for simplicity\n\ncombined_SSPs_long_select<-combined_SSPs_long%>%\n  filter(DHSCLUST<=5)\n\n#convert DHS cluster to a factor variable\n\ncombined_SSPs_long_select$DHSCLUSTfactor<-as.factor(combined_SSPs_long_select$DHSCLUST)\n\nlibrary(ggplot2)\n\n#ggplot code\n\nSSPplot <- ggplot(combined_SSPs_long_select, aes(x = year_month, y = Tmax, color = DHSCLUSTfactor, group = DHSCLUSTfactor)) +\n  geom_line(size = .75) +  \n  geom_point(size = 2, alpha = 0.7) +  # Optional: add points for clarity\n  facet_wrap(~ SSP, ncol = 2, labeller = label_both) +\n  scale_color_brewer(palette = \"Dark2\") +  # Higher contrast palette\n  scale_y_continuous(breaks = seq(32, 40, by = 0.05)) +\n  labs(\n    title = \"Scenario Temperature Data by DHS Cluster,January 2030 & 2050\",\n    subtitle = \"Comparing SSP 2-4.5 vs SSP 5-8.5\",\n    x = \"Date\",\n    y = \"Temperature (°C)\",\n    color = \"County\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\"),\n    panel.spacing = unit(1, \"lines\"),\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> ℹ Please use `linewidth` instead.\n\nSSPplot\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\nThis graph shows us cluster-level variation. Cluster 2 and 5 have the lowest projected values, while 1 and 4 have the highest.\n\nLet's look at the fifth cluster alone to zoom into the differences in temperature by scenario.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ncombined_SSPs_long_select_5<-combined_SSPs_long%>%\n  filter(DHSCLUST==\"5\")\n\n\nSSPplot2<-ggplot(combined_SSPs_long_select_5,aes(x = year_month, y = Tmax, color = SSP, group = SSP)) +\n  geom_line(size = 1.2) +\n  scale_color_manual(values = c(\"245\" = \"#1b9e77\", \"585\" = \"#d95f02\")) +  \n  scale_y_continuous(breaks = seq(36, 40, by =0.15)) +  # Even more fine y-axis \n  labs(\n    title = \"Average Temperature Over Time by SSP in DHS CLUSTER #5\",\n    x = \"Date\",\n    y = \"Temperature (°C)\",\n    color = \"SSP\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    legend.position = \"bottom\",\n    legend.title = element_text(face = \"bold\"),\n    plot.title = element_text(face = \"bold\")\n  )\n\nSSPplot2\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\nNow let's map out this data. We will create a separate map for each year per scenario. First, let's create a map for each SSP at 2030.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(ggspatial)\n#> Warning: package 'ggspatial' was built under R version 4.5.1\n\ncombined_SSPs_long_spatial<-left_join(ken_DHS_buffer, combined_SSPs_long)\n  \n#filter for only the 2030 values\ncombined_SSPs_long_spatial_2030<-combined_SSPs_long_spatial%>%\n  filter(year_month==\"2030-01\")\n\n\nmap2030<-ggplot(combined_SSPs_long_spatial_2030) +\n  geom_sf(aes(color = Tmax), size = 4, alpha = 0.8) +  # Use color for points\n  geom_sf(data = ken_ADM1_borders, color = \"black\", fill = NA, linewidth = 0.4) +\n  facet_wrap(~ SSP, ncol = 2, labeller = label_both) +\n  scale_color_viridis_c(option = \"plasma\", direction = -1) +\n  labs(\n    title = \"Projected Tmax by DHS Cluster in Kenya in January 2030, SSP 2-4.5 & SSP 5-8.5\",\n    subtitle = \"SSP\",\n    color = \"Tmax (°C)\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.text = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    panel.spacing = unit(1, \"lines\")\n  )\n\nmap2030\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\nBoth SSPs predict varied temperatures in the West, and hotter temperatures in the East, at different levels of extremity. Now let's create a map for each SSP at 2050.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\n#filter for only the 2050 values\ncombined_SSPs_long_spatial_2050<-combined_SSPs_long_spatial%>%\n  filter(year_month==\"2050-01\")\n\n\nmap2050<-ggplot(combined_SSPs_long_spatial_2050) +\n  geom_sf(aes(color = Tmax), size = 4, alpha = 0.8) +  # Use color for points\n  geom_sf(data = ken_ADM1_borders, color = \"black\", fill = NA, linewidth = 0.4) +\n  facet_wrap(~SSP, ncol = 2, labeller = label_both) +\n  scale_color_viridis_c(option = \"plasma\", direction = -1) +\n  labs(\n    title = \"Projected Tmax by DHS Cluster in Kenya, January 2050, SSP 2-4.5 & SSP 5-8.5\",\n    subtitle = \"SSP\",\n    color = \"Tmax (°C)\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.text = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    panel.spacing = unit(1, \"lines\")\n  )\n\nmap2050\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\nAt first glance, the geographic patterns and changes in temperature may not seem very different, but even slight increases will certainly have major and cascading impacts on health and agriculture if no steps are taken to adapt. The agricultural sector is very vulnerable to temperature variations that can alter growing seasons, reduce crop yields, and threaten food security ([IPCC report](https://www.ipcc.ch/report/ar6/wg2/downloads/report/IPCC_AR6_WGII_TechnicalSummary.pdf)) - under severe climate scenarios without adaptation, crop yield losses could range from 7% to 23% [@yuan2024impacts]. Human health is also at risk. Increased temperatures can directly cause heat stress, adverse pregnancy outcomes and poor mental health, while indirectly heat increases food insecurity or risk of infectious diseases that in turn affect health outcomes[@ebi2021hot]. Overall, climate adaptation measures will be required to reduce the impacts of increasing temperatures. Climate scenarios can help identify where and how soon this intervention will be required.\n\n# Conclusion\n\nThis post introduced you to one source of downscaled climate scenario data, CHC-CMIP6. We downloaded the data, cropped it to a specific geographic area, then aggregated it to a specific time frame. Lastly, we demonstrated how to create graphics that visualize this data. Our next post will go a step further by combining this data on future temperature conditions with child health outcomes, to explore if there is an association. We will again use CHC-CMIP6 scenario data and combine it with the 2022 DHS data from Kenya to model future levels of child malnutrition. While our previous post showed how short-term projections can inform early warning systems for more immediate action, using our scenarios can help with longer term planning, policy development and resource allocation to develop the infrastructure investments and nutrition sensitive programs that can improve health and resilience.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}