[
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "License",
    "section": "",
    "text": "1.1. “Contributor” means each individual or legal entity that creates, contributes to the creation of, or owns Covered Software.\n1.2. “Contributor Version” means the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor’s Contribution.\n1.3. “Contribution” means Covered Software of a particular Contributor.\n1.4. “Covered Software” means Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof.\n1.5. “Incompatible With Secondary Licenses” means\n(a) that the initial Contributor has attached the notice described\n    in Exhibit B to the Covered Software; or\n\n(b) that the Covered Software was made available under the terms of\n    version 1.1 or earlier of the License, but not also under the\n    terms of a Secondary License.\n1.6. “Executable Form” means any form of the work other than Source Code Form.\n1.7. “Larger Work” means a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software.\n1.8. “License” means this document.\n1.9. “Licensable” means having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License.\n1.10. “Modifications” means any of the following:\n(a) any file in Source Code Form that results from an addition to,\n    deletion from, or modification of the contents of Covered\n    Software; or\n\n(b) any new file in Source Code Form that contains any Covered\n    Software.\n1.11. “Patent Claims” of a Contributor means any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version.\n1.12. “Secondary License” means either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses.\n1.13. “Source Code Form” means the form of the work preferred for making modifications.\n1.14. “You” (or “Your”) means an individual or a legal entity exercising rights under this License. For legal entities, “You” includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, “control” means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity.\n\n\n\n2.1. Grants\nEach Contributor hereby grants You a world-wide, royalty-free, non-exclusive license:\n\nunder intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and\nunder Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version.\n\n2.2. Effective Date\nThe licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution.\n2.3. Limitations on Grant Scope\nThe licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor:\n\nfor any code that a Contributor has removed from Covered Software; or\nfor infringements caused by: (i) Your and any other third party’s modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or\nunder Patent Claims infringed by Covered Software in the absence of its Contributions.\n\nThis License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4).\n2.4. Subsequent Licenses\nNo Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3).\n2.5. Representation\nEach Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License.\n2.6. Fair Use\nThis License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents.\n2.7. Conditions\nSections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1.\n\n\n\n3.1. Distribution of Source Form\nAll distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients’ rights in the Source Code Form.\n3.2. Distribution of Executable Form\nIf You distribute Covered Software in Executable Form then:\n\nsuch Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and\nYou may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients’ rights in the Source Code Form under this License.\n\n3.3. Distribution of a Larger Work\nYou may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s).\n3.4. Notices\nYou may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies.\n3.5. Application of Additional Terms\nYou may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction.\n\n\n\nIf it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it.\n\n\n\n5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice.\n5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate.\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination.\n\n\n\nCovered Software is provided under this License on an “as is”\nbasis, without warranty of any kind, either expressed, implied, or\nstatutory, including, without limitation, warranties that the\nCovered Software is free of defects, merchantable, fit for a\nparticular purpose or non-infringing. The entire risk as to the\nquality and performance of the Covered Software is with You.\nShould any Covered Software prove defective in any respect, You\n(not any Contributor) assume the cost of any necessary servicing,\nrepair, or correction. This disclaimer of warranty constitutes an\nessential part of this License. No use of any Covered Software is\nauthorized under this License except under this disclaimer.\n\n\n\nUnder no circumstances and under no legal theory, whether tort\n(including negligence), contract, or otherwise, shall any\nContributor, or anyone who distributes Covered Software as\npermitted above, be liable to You for any direct, indirect,\nspecial, incidental, or consequential damages of any character\nincluding, without limitation, damages for lost profits, loss of\ngoodwill, work stoppage, computer failure or malfunction, or any\nand all other commercial damages or losses, even if such party\nshall have been informed of the possibility of such damages. This\nlimitation of liability shall not apply to liability for death or\npersonal injury resulting from such party’s negligence to the\nextent applicable law prohibits such limitation. Some\njurisdictions do not allow the exclusion or limitation of\nincidental or consequential damages, so this exclusion and\nlimitation may not apply to You.\n\n\n\nAny litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party’s ability to bring cross-claims or counter-claims.\n\n\n\nThis License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor.\n\n\n\n10.1. New Versions\nMozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number.\n10.2. Effect of New Versions\nYou may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward.\n10.3. Modified Versions\nIf you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License).\n10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses\nIf You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached.\n\n\n\nThis Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\nIf it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice.\nYou may add additional accurate notices of copyright ownership.\n\n\n\nThis Source Code Form is “Incompatible With Secondary Licenses”, as defined by the Mozilla Public License, v. 2.0."
  },
  {
    "objectID": "LICENSE.html#definitions",
    "href": "LICENSE.html#definitions",
    "title": "License",
    "section": "",
    "text": "1.1. “Contributor” means each individual or legal entity that creates, contributes to the creation of, or owns Covered Software.\n1.2. “Contributor Version” means the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor’s Contribution.\n1.3. “Contribution” means Covered Software of a particular Contributor.\n1.4. “Covered Software” means Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof.\n1.5. “Incompatible With Secondary Licenses” means\n(a) that the initial Contributor has attached the notice described\n    in Exhibit B to the Covered Software; or\n\n(b) that the Covered Software was made available under the terms of\n    version 1.1 or earlier of the License, but not also under the\n    terms of a Secondary License.\n1.6. “Executable Form” means any form of the work other than Source Code Form.\n1.7. “Larger Work” means a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software.\n1.8. “License” means this document.\n1.9. “Licensable” means having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License.\n1.10. “Modifications” means any of the following:\n(a) any file in Source Code Form that results from an addition to,\n    deletion from, or modification of the contents of Covered\n    Software; or\n\n(b) any new file in Source Code Form that contains any Covered\n    Software.\n1.11. “Patent Claims” of a Contributor means any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version.\n1.12. “Secondary License” means either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses.\n1.13. “Source Code Form” means the form of the work preferred for making modifications.\n1.14. “You” (or “Your”) means an individual or a legal entity exercising rights under this License. For legal entities, “You” includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, “control” means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity."
  },
  {
    "objectID": "LICENSE.html#license-grants-and-conditions",
    "href": "LICENSE.html#license-grants-and-conditions",
    "title": "License",
    "section": "",
    "text": "2.1. Grants\nEach Contributor hereby grants You a world-wide, royalty-free, non-exclusive license:\n\nunder intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and\nunder Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version.\n\n2.2. Effective Date\nThe licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution.\n2.3. Limitations on Grant Scope\nThe licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor:\n\nfor any code that a Contributor has removed from Covered Software; or\nfor infringements caused by: (i) Your and any other third party’s modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or\nunder Patent Claims infringed by Covered Software in the absence of its Contributions.\n\nThis License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4).\n2.4. Subsequent Licenses\nNo Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3).\n2.5. Representation\nEach Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License.\n2.6. Fair Use\nThis License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents.\n2.7. Conditions\nSections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1."
  },
  {
    "objectID": "LICENSE.html#responsibilities",
    "href": "LICENSE.html#responsibilities",
    "title": "License",
    "section": "",
    "text": "3.1. Distribution of Source Form\nAll distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients’ rights in the Source Code Form.\n3.2. Distribution of Executable Form\nIf You distribute Covered Software in Executable Form then:\n\nsuch Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and\nYou may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients’ rights in the Source Code Form under this License.\n\n3.3. Distribution of a Larger Work\nYou may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s).\n3.4. Notices\nYou may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies.\n3.5. Application of Additional Terms\nYou may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction."
  },
  {
    "objectID": "LICENSE.html#inability-to-comply-due-to-statute-or-regulation",
    "href": "LICENSE.html#inability-to-comply-due-to-statute-or-regulation",
    "title": "License",
    "section": "",
    "text": "If it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it."
  },
  {
    "objectID": "LICENSE.html#termination",
    "href": "LICENSE.html#termination",
    "title": "License",
    "section": "",
    "text": "5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice.\n5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate.\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination."
  },
  {
    "objectID": "LICENSE.html#disclaimer-of-warranty",
    "href": "LICENSE.html#disclaimer-of-warranty",
    "title": "License",
    "section": "",
    "text": "Covered Software is provided under this License on an “as is”\nbasis, without warranty of any kind, either expressed, implied, or\nstatutory, including, without limitation, warranties that the\nCovered Software is free of defects, merchantable, fit for a\nparticular purpose or non-infringing. The entire risk as to the\nquality and performance of the Covered Software is with You.\nShould any Covered Software prove defective in any respect, You\n(not any Contributor) assume the cost of any necessary servicing,\nrepair, or correction. This disclaimer of warranty constitutes an\nessential part of this License. No use of any Covered Software is\nauthorized under this License except under this disclaimer."
  },
  {
    "objectID": "LICENSE.html#limitation-of-liability",
    "href": "LICENSE.html#limitation-of-liability",
    "title": "License",
    "section": "",
    "text": "Under no circumstances and under no legal theory, whether tort\n(including negligence), contract, or otherwise, shall any\nContributor, or anyone who distributes Covered Software as\npermitted above, be liable to You for any direct, indirect,\nspecial, incidental, or consequential damages of any character\nincluding, without limitation, damages for lost profits, loss of\ngoodwill, work stoppage, computer failure or malfunction, or any\nand all other commercial damages or losses, even if such party\nshall have been informed of the possibility of such damages. This\nlimitation of liability shall not apply to liability for death or\npersonal injury resulting from such party’s negligence to the\nextent applicable law prohibits such limitation. Some\njurisdictions do not allow the exclusion or limitation of\nincidental or consequential damages, so this exclusion and\nlimitation may not apply to You."
  },
  {
    "objectID": "LICENSE.html#litigation",
    "href": "LICENSE.html#litigation",
    "title": "License",
    "section": "",
    "text": "Any litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party’s ability to bring cross-claims or counter-claims."
  },
  {
    "objectID": "LICENSE.html#miscellaneous",
    "href": "LICENSE.html#miscellaneous",
    "title": "License",
    "section": "",
    "text": "This License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor."
  },
  {
    "objectID": "LICENSE.html#versions-of-the-license",
    "href": "LICENSE.html#versions-of-the-license",
    "title": "License",
    "section": "",
    "text": "10.1. New Versions\nMozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number.\n10.2. Effect of New Versions\nYou may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward.\n10.3. Modified Versions\nIf you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License).\n10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses\nIf You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached."
  },
  {
    "objectID": "LICENSE.html#exhibit-a---source-code-form-license-notice",
    "href": "LICENSE.html#exhibit-a---source-code-form-license-notice",
    "title": "License",
    "section": "",
    "text": "This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/.\nIf it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice.\nYou may add additional accurate notices of copyright ownership."
  },
  {
    "objectID": "LICENSE.html#exhibit-b---incompatible-with-secondary-licenses-notice",
    "href": "LICENSE.html#exhibit-b---incompatible-with-secondary-licenses-notice",
    "title": "License",
    "section": "",
    "text": "This Source Code Form is “Incompatible With Secondary Licenses”, as defined by the Mozilla Public License, v. 2.0."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "href": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "title": "Contributor Covenant Code of Conduct",
    "section": "Enforcement Guidelines",
    "text": "Enforcement Guidelines\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n1. Correction\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n2. Warning\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n3. Temporary Ban\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n4. Permanent Ban\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "blog-post-workflow.html",
    "href": "blog-post-workflow.html",
    "title": "Blog Post Workflow",
    "section": "",
    "text": "To work on the blog, you’ll need the following:\n\nR\nRStudio\nGit\nA few particular R packages\n\nIf you’re working on your own machine, follow the instructions below to get this software installed.\nThe MPC also hosts a server instance of R and RStudio, which you can access using your UMN login credentials. If you prefer to work on the server, then R, RStudio, and Git will already be installed. However, you will still need to install the indicated R packages and configure your Git setup (if you haven’t done so before), so we still suggest reading through these instructions.\n\n\nTo install R, visit the Comprehensive R Archive Network (CRAN) and choose the appropriate download link for your operating system.\n\nRStudio is an interactive development environment (IDE) for R that provides an interface and code editing tools that make it much, much easier to write and edit R code.\nThe DHS Research Hub is organized as an RStudio Project, which requires RStudio. You can download RStudio here.\n\nWhen you’ve got RStudio set up, install these R packages by running the following in the RStudio console:\n\n# For writing blog posts\ninstall.packages(\"rmarkdown\")\ninstall.packages(\"knitr\")\n\n# For help setting up Git\ninstall.packages(\"usethis\")\ninstall.packages(\"gert\")\ninstall.packages(\"gitcreds\")\n\n\n\n\n\n\n\nTip\n\n\n\nIf you have trouble installing any of these packages, try to install them in a fresh RStudio session (in the RStudio toolbar, select Session &gt; Restart R).\n\n\n\n\nThe DHS Research Hub blog materials exist in both a public and private format. When you’re working on the blog, you’ll be working on the private site, which is hosted on the UMN Enterprise GitHub server at https://github.umn.edu/mpc/dhs-research-hub.\nThe UMN GitHub server is accessible only to people affiliated with UMN. By working in this environment, we can develop and edit new posts without having to worry about them becoming visible on the public site prematurely. Also, it allows us to store files necessary for certain posts (e.g. IPUMS data files) without making those files publicly visible. Members of the blog “admin” team will be responsible for migrating completed posts to the public version of the site.\nSince you’re affiliated with UMN, you automatically have access to an account on UMN GitHub. To initialize an account, visit https://github.umn.edu and log in with your University Internet ID and password.\n\nTo interact with GitHub, you’ll need to install Git on your local machine. Git is the version control software that allows us to track the blog’s history and manage line-by-line changes to files as we edit new posts.\n\nMacOS comes with Git already installed. To confirm, you can check its location by running which git in the Mac Terminal. You can also check the version you have installed by running git --version.\nIf for some reason Git is not installed, use the Install Git using Homebrew instructions to install it.\n\nUsers of other operating systems should download the appropriate git for their operating system.\n\nNext, we’ll link RStudio and Git. This adds a new tab to your RStudio interface where you can see your files being tracked by Git in a convenient point-and-click format.\nIn the RStudio toolbar, select Tools &gt; Global Options and locate the Git/SVN tab. Ensure that the box shown below is checked, and then enter the location of the executable file. To find the git executable\n\n\non MacOS: run which git in Terminal\n\non Windows: look for git.exe in your file explorer (most likely in Program Files)\n\n\n\n\n\n\n\n\n\n\nFinally, we’ll provide Git with the username and email associated with our UMN GitHub account. We’ll also need to generate a Personal Access Token (PAT) for our account. The PAT functions like a password that allows you to interact with your UMN GitHub account from R and the command line.\nIf you’ve installed the packages listed above, you can use R code (rather than the command line) to configure your credentials. This is what we demonstrate below.\nFirst, set the username and email address associated with your UMN GitHub account. For example, I’d run:\n\ngert::git_config_global_set(\"user.name\", \"Finn Roberts\")\ngert::git_config_global_set(\"user.email\", \"robe2037@umn.edu\")\n\n\n\n\n\n\n\nNote\n\n\n\nYou don’t necessarily need to store your credentials to use Git, but if you don’t, you’ll have to enter them in a popup window each time you interact with GitHub from R or the command line.\n\n\nNext, create a PAT for your account. Run the following in your RStudio console to launch a webpage where you can configure a new PAT:\n\nusethis::create_github_token(host = \"https://github.umn.edu\")\n\nYou can leave the default boxes checked and click the green Generate Token button. This should display a long string of digits—this is your new PAT. Don’t close this page yet! Return to your RStudio console and run:\n\ngitcreds::gitcreds_set(\"https://github.umn.edu\")\n\nThis will prompt you to enter a new token. Follow the instructions to copy and paste the PAT you just generated in your browser and press Enter. From now on, RStudio and Git will be able to access your UMN GitHub account automatically.\n\n\n\n\n\n\nNote\n\n\n\nIf you have a personal GitHub account at https://github.com you could repeat this process substituting \"https://github.com\" for \"https://github.umn.edu\", and Git will automatically choose the right credentials based on the repository associated with your project.\n\n\n\nNow that we have Git configured, we can download (or clone) a copy of the blog materials from UMN GitHub.\nOpen RStudio and navigate to File &gt; New Project, then select Version Control:\n\n\n\n\n\n\n\n\nChoose Git to clone the project from a GitHub repository:\n\n\n\n\n\n\n\n\nOn the next menu page, enter the address for the UMN GitHub repository: https://github.umn.edu/mpc/dhs-research-hub/\nHit Tab and the project directory name should populate automatically. If not, enter dhs-research-hub as the directory name:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nMake sure to clone the private version of the repository (the one located at github.umn.edu), not the public version (located at github.com).\n\n\nIn the third field, choose the location where you would like to store the blog materials on your computer. This can be anywhere that makes sense with your personal file organization approach.\n\n\nWhen choosing a place to save this project, do not save to a network drive. This seems to cause RStudio to crash!\nFinally, click Create Project. After a short bit, RStudio will relaunch and open the new project. If you adjust the windows to show the Files (left) and Git (right) tabs, you should see something like this:\n\n\n\nYou have now downloaded a copy of the DHS Research Hub blog to your computer!\nMoreover, because you’ve connected these files to a GitHub repository, the RStudio Project will now keep track of changes you make to the files in this folder, and it will prompt you to upload your changes back to GitHub: as you add, edit, or delete files, a list of changes will appear in the Git tab.\n\n\n\n\n\n\nNote\n\n\n\nTo ensure that RStudio recognizes the project is being used with Git, make sure to open the .Rproj file before working on any of the blog materials.\nTo open the project, simply click on the dhs-research-hub.Rproj file or navigate to File &gt; Open Project. (You only need to do this once at the start of your R session.)"
  },
  {
    "objectID": "blog-post-workflow.html#set-up-r-and-rstudio",
    "href": "blog-post-workflow.html#set-up-r-and-rstudio",
    "title": "Blog Post Workflow",
    "section": "",
    "text": "To install R, visit the Comprehensive R Archive Network (CRAN) and choose the appropriate download link for your operating system.\n\nRStudio is an interactive development environment (IDE) for R that provides an interface and code editing tools that make it much, much easier to write and edit R code.\nThe DHS Research Hub is organized as an RStudio Project, which requires RStudio. You can download RStudio here.\n\nWhen you’ve got RStudio set up, install these R packages by running the following in the RStudio console:\n\n# For writing blog posts\ninstall.packages(\"rmarkdown\")\ninstall.packages(\"knitr\")\n\n# For help setting up Git\ninstall.packages(\"usethis\")\ninstall.packages(\"gert\")\ninstall.packages(\"gitcreds\")\n\n\n\n\n\n\n\nTip\n\n\n\nIf you have trouble installing any of these packages, try to install them in a fresh RStudio session (in the RStudio toolbar, select Session &gt; Restart R)."
  },
  {
    "objectID": "blog-post-workflow.html#configure-git-and-access-blog-materials",
    "href": "blog-post-workflow.html#configure-git-and-access-blog-materials",
    "title": "Blog Post Workflow",
    "section": "",
    "text": "The DHS Research Hub blog materials exist in both a public and private format. When you’re working on the blog, you’ll be working on the private site, which is hosted on the UMN Enterprise GitHub server at https://github.umn.edu/mpc/dhs-research-hub.\nThe UMN GitHub server is accessible only to people affiliated with UMN. By working in this environment, we can develop and edit new posts without having to worry about them becoming visible on the public site prematurely. Also, it allows us to store files necessary for certain posts (e.g. IPUMS data files) without making those files publicly visible. Members of the blog “admin” team will be responsible for migrating completed posts to the public version of the site.\nSince you’re affiliated with UMN, you automatically have access to an account on UMN GitHub. To initialize an account, visit https://github.umn.edu and log in with your University Internet ID and password.\n\nTo interact with GitHub, you’ll need to install Git on your local machine. Git is the version control software that allows us to track the blog’s history and manage line-by-line changes to files as we edit new posts.\n\nMacOS comes with Git already installed. To confirm, you can check its location by running which git in the Mac Terminal. You can also check the version you have installed by running git --version.\nIf for some reason Git is not installed, use the Install Git using Homebrew instructions to install it.\n\nUsers of other operating systems should download the appropriate git for their operating system.\n\nNext, we’ll link RStudio and Git. This adds a new tab to your RStudio interface where you can see your files being tracked by Git in a convenient point-and-click format.\nIn the RStudio toolbar, select Tools &gt; Global Options and locate the Git/SVN tab. Ensure that the box shown below is checked, and then enter the location of the executable file. To find the git executable\n\n\non MacOS: run which git in Terminal\n\non Windows: look for git.exe in your file explorer (most likely in Program Files)\n\n\n\n\n\n\n\n\n\n\nFinally, we’ll provide Git with the username and email associated with our UMN GitHub account. We’ll also need to generate a Personal Access Token (PAT) for our account. The PAT functions like a password that allows you to interact with your UMN GitHub account from R and the command line.\nIf you’ve installed the packages listed above, you can use R code (rather than the command line) to configure your credentials. This is what we demonstrate below.\nFirst, set the username and email address associated with your UMN GitHub account. For example, I’d run:\n\ngert::git_config_global_set(\"user.name\", \"Finn Roberts\")\ngert::git_config_global_set(\"user.email\", \"robe2037@umn.edu\")\n\n\n\n\n\n\n\nNote\n\n\n\nYou don’t necessarily need to store your credentials to use Git, but if you don’t, you’ll have to enter them in a popup window each time you interact with GitHub from R or the command line.\n\n\nNext, create a PAT for your account. Run the following in your RStudio console to launch a webpage where you can configure a new PAT:\n\nusethis::create_github_token(host = \"https://github.umn.edu\")\n\nYou can leave the default boxes checked and click the green Generate Token button. This should display a long string of digits—this is your new PAT. Don’t close this page yet! Return to your RStudio console and run:\n\ngitcreds::gitcreds_set(\"https://github.umn.edu\")\n\nThis will prompt you to enter a new token. Follow the instructions to copy and paste the PAT you just generated in your browser and press Enter. From now on, RStudio and Git will be able to access your UMN GitHub account automatically.\n\n\n\n\n\n\nNote\n\n\n\nIf you have a personal GitHub account at https://github.com you could repeat this process substituting \"https://github.com\" for \"https://github.umn.edu\", and Git will automatically choose the right credentials based on the repository associated with your project.\n\n\n\nNow that we have Git configured, we can download (or clone) a copy of the blog materials from UMN GitHub.\nOpen RStudio and navigate to File &gt; New Project, then select Version Control:\n\n\n\n\n\n\n\n\nChoose Git to clone the project from a GitHub repository:\n\n\n\n\n\n\n\n\nOn the next menu page, enter the address for the UMN GitHub repository: https://github.umn.edu/mpc/dhs-research-hub/\nHit Tab and the project directory name should populate automatically. If not, enter dhs-research-hub as the directory name:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nMake sure to clone the private version of the repository (the one located at github.umn.edu), not the public version (located at github.com).\n\n\nIn the third field, choose the location where you would like to store the blog materials on your computer. This can be anywhere that makes sense with your personal file organization approach.\n\n\nWhen choosing a place to save this project, do not save to a network drive. This seems to cause RStudio to crash!\nFinally, click Create Project. After a short bit, RStudio will relaunch and open the new project. If you adjust the windows to show the Files (left) and Git (right) tabs, you should see something like this:\n\n\n\nYou have now downloaded a copy of the DHS Research Hub blog to your computer!\nMoreover, because you’ve connected these files to a GitHub repository, the RStudio Project will now keep track of changes you make to the files in this folder, and it will prompt you to upload your changes back to GitHub: as you add, edit, or delete files, a list of changes will appear in the Git tab.\n\n\n\n\n\n\nNote\n\n\n\nTo ensure that RStudio recognizes the project is being used with Git, make sure to open the .Rproj file before working on any of the blog materials.\nTo open the project, simply click on the dhs-research-hub.Rproj file or navigate to File &gt; Open Project. (You only need to do this once at the start of your R session.)"
  },
  {
    "objectID": "posts/2024-02-03-climate-theory/index.html",
    "href": "posts/2024-02-03-climate-theory/index.html",
    "title": "Developing Robust Conceptual Models in Climate Change and Health Research",
    "section": "",
    "text": "Unpacking the relationship between climate change and health requires not only technical skills, but also a strong theoretical foundation. Climate change, health, and their relationships are all complex. Researchers begin by conceptualizing—for their specific questions—1) the nature of the climate event, 2) the details of the health outcome, and 3) the temporal and spatial relationships between the climate and health phenomena of interest.\nBeyond these three elements, contextual factors are crucial for identifying the complex causal pathways among climate change and health. Figure 1 illustrates how the pathway from a climate event, its manifestation in the environment, and its impact on various health outcomes is embedded within larger contexts. As suggested by the gray box on the right, individuals will be impacted by climate change in unique ways based on their demographic characteristics and social determinants that affect their lived experiences. The gray box on the left illustrates how environmental and institutional contexts will also influence relationships between climatic events and health. Contexts influence the impact of exposures on individuals as well as their mitigation and adaptation strategies in response to climate risks."
  },
  {
    "objectID": "posts/2024-02-03-climate-theory/index.html#building-a-conceptual-model",
    "href": "posts/2024-02-03-climate-theory/index.html#building-a-conceptual-model",
    "title": "Developing Robust Conceptual Models in Climate Change and Health Research",
    "section": "Building a conceptual model",
    "text": "Building a conceptual model\nBelow, we provide the steps in creating a tailored conceptual model for climate change and health research.\n\n1. Assessing the temporal and spatial nature of climate risk\nRisks arising from climate change vary in their temporal and spatial scales. In terms of timing, risks may be acute or protracted. Acute risks arise when one-time exposure to a climate event is sufficient to trigger health outcomes, for example, when flooding makes water unsafe for drinking. Protracted risks, in contrast, arise from sustained exposure to climate phenomenon, such as the inhalation of dust over the course of enduring dry periods. The impact of climate change is also spatially variable. While some climate events affect wide areas, others’ scope is limited to discrete locations. Determining the type of risk depends on both the nature of the climate event and the health outcome studied. Identifying the temporal and spatial dimensions of risk provide the basis for decisions concerning temporal aggregation of climate data, as well as the length of expected lags between initial exposure to a climate event and the manifestation of the health outcome.\n\n\n2. Incorporating social and behavioral context\nCertain climate events are known to have deleterious effects on humans. For example, exposure to extremely high temperatures during the first trimester of pregnancy increases the risk of low birth-weight babies.2 Basic biological truths such as this are insufficient, however, to fully assess the impact of climate events on individual health because individuals have dramatically different access to resources, opportunities, and constraints. A pregnant person who lives in an air-conditioned house will experience extreme temperatures very differently than a person who is houseless. Demographic characteristics, such as age, gender, wealth, and partnership status matter when assessing climate impacts.\nFurthermore, the characteristics of societies (e.g., rural versus urban, gender roles, livelihoods) matter. Consider rising temperatures in nomadic versus other types of communities.3 For both, temperature change may make it harder to access water. In nomadic communities, the result could be men driving herds further from the community and thus staying away longer, while in other communities, the result could be that children tasked with collecting water find the task more physically demanding. Who and how individuals are affected by water shortages will vary depending on community norms and roles. Community characteristics will also affect the instigation and nature of mitigation and adaptation efforts. While analyses that map the nature of climate change over time provide a useful starting point, they cannot fully capture the individual- and community-specific impacts of climate change.3\n\n\n3. Understanding environmental and institutional contexts\nEnvironmental and institutional contexts are also influential in shaping causal pathways between climate change and health. The physical environment, such as altitude and the demarcation of seasons, can provide some level of protection from some climatic events. For instance, a small reduction in annual rainfall can have a devastating effect in an arid location where there is a close correspondence between a rainy season and agricultural production.4 The same reduction in rainfall might have only a minor impact in a location where annual precipitation is diffused throughout the year and is less closely tied to the agricultural season. Understanding such differences is important for selecting accurate measurements. In the former location, the rain shortfall might best be measured through the length of the rainy season. In the latter location, considering rainfall deviation from a monthly or annual average could be more appropriate.4\nInstitutional contexts include the built environment, such as the presence of roads, wells, and irrigation systems, as well as organizations designed to facilitate human capabilities, such as political, healthcare, and education systems. Local governments’ capacities to intervene to protect populations faced with climate risks can reduce negative health outcomes. Healthcare systems affect the accessibility of treatment (both physically and financially), while education systems provide individuals with the knowledge of when and how to respond to climatic events. Climate change and health research that fails to capture these contextual effects can lead to faulty conclusions."
  },
  {
    "objectID": "posts/2024-02-03-climate-theory/index.html#conclusion",
    "href": "posts/2024-02-03-climate-theory/index.html#conclusion",
    "title": "Developing Robust Conceptual Models in Climate Change and Health Research",
    "section": "Conclusion",
    "text": "Conclusion\nTheorizing the core relationship among specific climate events and specific health outcomes is the first step in developing a conceptual model but is insufficient to fully capture complex causal pathways. Individual characteristics, social determinants of health, and environmental and institutional environments are also critical. Informed and clearly identified spatial and temporal measurement of climate exposures is necessary, and these exposures should be thoughtfully, appropriately, and explicitly linked to the particular health outcomes of interest. Community-focused expertise and stakeholder engagement is vital to fully understand and incorporate how broader contexts interact with local circumstances to uniquely influence how climate change is experienced.\n\nFor more information\nTo learn more about the technical modeling implications of climate-change-and-health conceptual models, see Dorélien and Grace (2023).4\nTo see a specific model of the impact of climate change on women’s reproductive health in Africa, see Grace (2017).3\nFor further delineation of the elements in climate-change-and-health models (in the U.S. context), see Balbus et al. (2016).5"
  },
  {
    "objectID": "posts/2024-02-02-download-dhs-data/index.html",
    "href": "posts/2024-02-02-download-dhs-data/index.html",
    "title": "Obtaining Data from IPUMS DHS",
    "section": "",
    "text": "The Demographic and Health Surveys Program (DHS) is the leading source of population health data for low- and middle-income countries around the world. IPUMS DHS disseminates a harmonized version of the DHS survey results in which variables are integrated across time and space, facilitating comparative and longitudinal analysis. Furthermore, IPUMS DHS provides a web interface and streamlined documentation to make the data discovery and download process easier."
  },
  {
    "objectID": "posts/2024-02-02-download-dhs-data/index.html#browse-data",
    "href": "posts/2024-02-02-download-dhs-data/index.html#browse-data",
    "title": "Obtaining Data from IPUMS DHS",
    "section": "Browse data",
    "text": "Browse data\nUsers can browse the available data using the IPUMS DHS data selection interface, which includes sample and variable availability, descriptions, codes, and more.\nFor more information about how to use the interface, see the IPUMS DHS user guide."
  },
  {
    "objectID": "posts/2024-02-02-download-dhs-data/index.html#select-data",
    "href": "posts/2024-02-02-download-dhs-data/index.html#select-data",
    "title": "Obtaining Data from IPUMS DHS",
    "section": "Select data",
    "text": "Select data\nOnce you’ve selected the samples and variables you want to include in your data extract, click View Cart to review your selections. If you’re satisfied with the contents of your extract, click Create Data Extract.\n\n\n\n\n\n\n\n\nIPUMS DHS allows you to select one of several output file formats. On this blog, we will use the default fixed-width (.dat) file option, which is the format expected by the data-reading functions provided in ipumsr.\n\n\n\n\n\n\n\n\nClick Submit Extract to submit your extract for processing on the IPUMS servers. You’ll receive an email when your extract is complete and ready to download."
  },
  {
    "objectID": "posts/2024-02-02-download-dhs-data/index.html#download-data",
    "href": "posts/2024-02-02-download-dhs-data/index.html#download-data",
    "title": "Obtaining Data from IPUMS DHS",
    "section": "Download data",
    "text": "Download data\nClick the green download button to download the compressed data file for your extract.\nYou will also need to download an associated metadata (DDI) file. This is an XML file that contains parsing instructions for the fixed-width data file as well as descriptive information about the variables contained in an extract.\n\n\nDDI stands for Data Documentation Initiative, an international standard for documenting data obtained in survey research.\nYou can do so by right clicking the DDI link and selecting Save link as….\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe specific text included in the dropdown may differ based on the browser that you are using. For instance, Safari displays the option Download Linked File As….\nThe important thing is that you download the DDI file in .xml format, not .html format."
  },
  {
    "objectID": "posts/2024-02-01-getting-started-with-r/index.html",
    "href": "posts/2024-02-01-getting-started-with-r/index.html",
    "title": "An Introduction to R",
    "section": "",
    "text": "The IPUMS DHS Climate Change and Health Research Hub is designed to introduce spatial data concepts for researchers who work with population health survey data.\nTo do so, the blog will provide both conceptual content describing ways in which spatial data can be appropriately included in population research as well as technical content demonstrating how to implement some of these approaches using statistical software.\nTechnical content will rely primarily on the R programming language. Not only is R one of the most popular platforms for data analysis around the world, but its open-source nature aligns well with IPUMS values. R is freely available for Windows, MacOS, and a wide variety of UNIX platforms and similar systems (including FreeBSD and Linux)."
  },
  {
    "objectID": "posts/2024-02-01-getting-started-with-r/index.html#getting-started-with-r",
    "href": "posts/2024-02-01-getting-started-with-r/index.html#getting-started-with-r",
    "title": "An Introduction to R",
    "section": "Getting started with R",
    "text": "Getting started with R\nTo download R, visit the Comprehensive R Archive Network (CRAN) and choose the appropriate download link for your operating system.\n\n\n\n\n\n\nR Version Requirements\n\n\n\nThis blog is designed to work with R 4.1.0 and later. The 4.1.0 release included several notable updates that are used in this blog, including the introduction of the native pipe operator |&gt;.\nIf you’ve previously downloaded R, you’ll need to update your R version to run some of the code presented in this blog.\n\n\nThere are countless free resources available for learning R, from foundational knowledge to niche topics. Here are a few of our favorite resources to help you get started:\n\n\nR for Data Science for beginners\n\nAdvanced R for a deeper dive\n\nRSpatial and Geocomputation with R for analysis with spatial data\n\nggplot2 for data visualization\n\nMastering Shiny for interactive applications\n\nR Markdown: The Definitive Guide for producing annotated code, word documents, presentations, web pages, and more\n\nR-bloggers for regular news and tutorials\n\nAdditionally, you can always get help on Stack Overflow and—for packages hosted on GitHub—their GitHub issues page. No matter what question you have, you’re unlikely to be the first person to encounter it, so it’s always worth checking to see whether your problem has been solved in the past."
  },
  {
    "objectID": "posts/2024-02-01-getting-started-with-r/index.html#essential-packages",
    "href": "posts/2024-02-01-getting-started-with-r/index.html#essential-packages",
    "title": "An Introduction to R",
    "section": "Essential packages",
    "text": "Essential packages\nSeveral packages will come into frequent use on this blog.\nipumsr\nThe ipumsr package contains functions that make it easier to load IPUMS data into R.\n\n\n\n   © IPUMS (MPL-2.0) \nFor IPUMS DHS, the most relevant of these is read_ipums_micro(), which allows you to load a fixed-width data file along with associated metadata.\nipumsr also contains functions to interact with variable metadata after loading, like ipums_var_info(), ipums_val_labels(), and so on.\nAs mentioned above, ipumsr also contains client tools for interacting with the IPUMS API. This allows users to request and download IPUMS data entirely within their R environment. While not available for IPUMS DHS, users of supported IPUMS collections can learn more from the API workflows introduced on the ipumsr website\ntidyverse\nThe tidyverse package actually refers to a family of related packages. Installing tidyverse will actually install each of these component packages:\n\n\n\n   © RStudio, Inc. (MIT) \n\n\nggplot2 for data visualization\n\ndplyr for data manipulation\n\ntidyr for data tidying\n\nreadr for data import\n\npurrr for functional programming\n\ntibble for tibbles (a modern re-imagining of data frames)\n\nstringr for string manipulation\n\nforcats for factor handling\n\nIt’s possible to call library(tidyverse) to load all the packages in the tidyverse collection, but in most cases it’s best to individually load the specific packages you need for a given R script. This allows you and other users to more easily identify the specific packages required to run your code. It also makes your code more accessible—other users won’t have to have the entire tidyverse collection installed to run your code, only the specific packages that are actually required.\nIn general, this blog will follow the tidyverse style guide where possible. So-called “tidy” conventions are designed with the express purpose of making code and console output more human readable.\n\n\n\n\n\n\nTip\n\n\n\nSometimes, human readability imposes a performance cost: in our experience, IPUMS DHS datasets are small enough that this is not an issue. For larger datasets, we recommend exploring the data.table package instead.\n\n\nsf\n\n\n\n   © Edzer Pebesma (GPL-2 | MIT) \nsf, which stands for simple features, is the main R package for working with spatial vector data.\nsf represents spatial data in a “tidy” format that resembles those used by tidyverse packages mentioned above. sf objects contain tabular data along with a record of the geometry associated with each individual record.\nThis format makes it easy to perform spatial operations, attach spatial information to non-spatial data sources (like DHS surveys), and generate maps.\nterra\n\n\n\n   © Robert J. Hijmans et al. (GPL &gt;=3) \nterra provides a general framework for working with spatial data in both raster and vector format.\nWhile sf provides an alternative approach to working with vector data, terra’s raster handling stands alone and provides robust methods to quickly index, aggregate, and manipulate raster data.\nBecause of its speed and simplicity, terra has superseded the long-lived raster package, which is being retired. You may still see online resources that reference the raster package, but we suggest relying only on terra."
  },
  {
    "objectID": "posts/2024-02-04-dhs-chirps/index.html",
    "href": "posts/2024-02-04-dhs-chirps/index.html",
    "title": "Attaching CHIRPS Precipitation Data to DHS Surveys",
    "section": "",
    "text": "We know that health outcomes are significantly impacted by individuals’ environmental context: excessive rainfall can flood local infrastructure1; warmer temperatures can expand the range of common disease vectors2; and drought can decimate crop-growing regions.3 However, survey data like those from The DHS Program often provide only a limited view of the environmental trends in which individuals are embedded.\nDeveloping a more holistic understanding of the role of environmental conditions in health outcomes therefore requires integrating external data sources with the survey data from DHS.\nIn this post we’ll demonstrate how to obtain raw precipitation data from the Climate Hazards Center InfraRed Precipitation with Station dataset (CHIRPS) and attach that data to survey responses from IPUMS DHS."
  },
  {
    "objectID": "posts/2024-02-04-dhs-chirps/index.html#ipums-dhs-survey-data",
    "href": "posts/2024-02-04-dhs-chirps/index.html#ipums-dhs-survey-data",
    "title": "Attaching CHIRPS Precipitation Data to DHS Surveys",
    "section": "IPUMS DHS survey data",
    "text": "IPUMS DHS survey data\nTo get started, we’ll download a data file (or extract, in IPUMS terms) from IPUMS DHS and load it into R. The extract in this post contains the HWHAZWHO variable (which contains the height-for-age Z-score) along with several pre-selected variables for the 2010 Burkina Faso sample. If you need a refresher on how to download IPUMS DHS data, see the Downloading IPUMS DHS Data post.\n\n\n\n   © IPUMS (MPL-2.0) \nWe’ve downloaded and stored our XML codebook and compressed data file in the data/dhs directory. Be sure to update this path based on your local file setup, so you can follow along.\nTo simplify our output, we’ll select only a subset of the variables included in the extract:\n\nlibrary(ipumsr)\nlibrary(dplyr)\n\n# Load IPUMS DHS extract\ndhs &lt;- read_ipums_micro(\n  ddi = \"data/dhs/idhs_00018.xml\",\n  data_file = \"data/dhs/idhs_00018.dat.gz\",\n  verbose = FALSE\n)\n\n# Select a subset of variables\ndhs &lt;- dhs |&gt; \n  select(SAMPLE, YEAR, IDHSPID, IDHSHID, DHSID, URBAN, HWHAZWHO)\n\ndhs\n#&gt; # A tibble: 15,044 × 7\n#&gt;    SAMPLE                     YEAR IDHSPID      IDHSHID DHSID URBAN   HWHAZWHO  \n#&gt;    &lt;int+lbl&gt;                 &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt; &lt;int+l&gt; &lt;int+lbl&gt; \n#&gt;  1 85404 [Burkina Faso 2010]  2010 85404      … 85404 … BF20… 2 [Rur… -264      \n#&gt;  2 85404 [Burkina Faso 2010]  2010 85404      … 85404 … BF20… 2 [Rur… -113      \n#&gt;  3 85404 [Burkina Faso 2010]  2010 85404      … 85404 … BF20… 2 [Rur…  -13      \n#&gt;  4 85404 [Burkina Faso 2010]  2010 85404      … 85404 … BF20… 2 [Rur… -291      \n#&gt;  5 85404 [Burkina Faso 2010]  2010 85404      … 85404 … BF20… 2 [Rur… -211      \n#&gt;  6 85404 [Burkina Faso 2010]  2010 85404      … 85404 … BF20… 2 [Rur… 9999 [NIU…\n#&gt;  7 85404 [Burkina Faso 2010]  2010 85404      … 85404 … BF20… 2 [Rur… 9999 [NIU…\n#&gt;  8 85404 [Burkina Faso 2010]  2010 85404      … 85404 … BF20… 2 [Rur… -185      \n#&gt;  9 85404 [Burkina Faso 2010]  2010 85404      … 85404 … BF20… 2 [Rur… 9999 [NIU…\n#&gt; 10 85404 [Burkina Faso 2010]  2010 85404      … 85404 … BF20… 2 [Rur…  -88      \n#&gt; # ℹ 15,034 more rows\n\nThis gives us a tabular data source containing 15,044 individual DHS survey responses for 7 variables. Of particular note is the DHSID variable (which stores the identifier for the location of the survey response)."
  },
  {
    "objectID": "posts/2024-02-04-dhs-chirps/index.html#dhs-cluster-coordinates",
    "href": "posts/2024-02-04-dhs-chirps/index.html#dhs-cluster-coordinates",
    "title": "Attaching CHIRPS Precipitation Data to DHS Surveys",
    "section": "DHS cluster coordinates",
    "text": "DHS cluster coordinates\nTo meaningfully attach environmental data to our DHS survey responses, we’ll need to know the location where each survey response was collected. Fortunately, the DHS Program provides GPS coordinates for each surveyed household grouping, or cluster.\n\n\n\n\n\n\nDHS Cluster Displacement\n\n\n\nIt’s important to note that the GPS coordinates provided by The DHS Program do not actually reflect the exact location of the clusters. In fact, the coordinates provided are randomly displaced from their true locations, such that:\n\nurban clusters are displaced up to 2 kilometers in any direction.\n99% of rural clusters are displaced up to 5 kilometers in any direction.\n1% of rural clusters are displaced up to 10 kilometers in any direction.\ndisplaced coordinates do not cross the country boundary and stay within the DHS survey region.\n\nThe current demonstration doesn’t require a precise location of each cluster, so we will ignore this detail. However, for more fine-grained analyses (e.g. road network analyses), you may need to take displacement into account.\nSee the DHS GPS data collection documentation for more details about the DHS cluster point displacement methodology.\n\n\nIPUMS DHS does not yet disseminate DHS cluster coordinates directly. For now, to obtain the GPS coordinates for a specific sample, you’ll have to log into your account from The DHS Program. Specify your country of interest, and, on the line for the appropriate sample year, click the link to download the GPS coordinate data under the heading GPS Datasets. (Again, for this example, we’re using Burkina Faso’s 2010 sample.)\n\n\nIPUMS DHS has recently received permission and funding to distribute DHS GPS data. Stay tuned, as these data will soon be available via IPUMS!\nYou’ll be presented with a new page containing a list of download links. Scroll down to the Geographic Datasets section. You have the option of downloading the file as either a shapefile (.shp) or a comma delimited file (.csv). For our purposes, we will download the shapefile, which contains spatial information in a format that can be easily interpreted by R (as well as by external GIS software).\nFor the Burkina Faso 2010 sample, the file should be named BFGE61FL. If you see a different file name, make sure you’re working with the correct survey year.\nVector data\nOur DHS cluster coordinates are what’s known as vector data. Vector data refer to spatial data that represent geographic features using geometric shapes like points, lines, and polygons.\n\n\nBasic features of the vector data model4\n\nIn R, the sf package provides an intuitive tabular framework for working with vector data. sf objects look much like a familiar tibble or data.frame, but also include an additional geometry column, which stores the spatial features that correspond to each set of observations.\n\n\n\n\n\n\n\n\n   © Edzer Pebesma (GPL-2 | MIT) \nInstalling sf\nsf requires three operating system dependencies:\n\n\nGEOS for geometrical operations on projected coordinates\n\nPRØJ for coordinate reference system conversion and transformation\n\nGDAL for driver options\n\nMake sure to follow these instructions to ensure that you set up GEOS, PRØJ, and GDAL when installing sf. The installation instructions may vary slightly, depending on your operating system. You may also need to update R, and then run install.packages(\"sf\").\nLoading cluster coordinates\nOnce sf is installed, we can use st_read() to load the file of GPS coordinate data we downloaded above. We’ve stored our shapefile in the data/gps directory. Again, make sure to adjust this path based on the location where you saved the file on your own system.\n\n\nA shapefile is actually a collection of several files; the primary file will have the .shp extension. Other files contain relevant metadata about the geometries contained in the .shp file (for instance, projection or index information).\n\nlibrary(sf)\n\n# Load the 2010 BF cluster coordinate shapefile\nbf_gps &lt;- st_read(\"data/gps/BFGE61FL/BFGE61FL.shp\")\n#&gt; Reading layer `BFGE61FL' from data source \n#&gt;   `/Users/robe2037/Documents/projects/dhs-research-hub/posts/2024-02-04-dhs-chirps/data/gps/BFGE61FL/BFGE61FL.shp' \n#&gt;   using driver `ESRI Shapefile'\n#&gt; Simple feature collection with 573 features and 20 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -5.426079 ymin: 5.684342e-14 xmax: 1.957316 ymax: 14.86258\n#&gt; Geodetic CRS:  WGS 84\n\nOur resulting dataset looks something like a tibble, except that it contains a header describing a simple feature collection with 573 features and 20 fields:\n\nbf_gps\n#&gt; Simple feature collection with 573 features and 20 fields\n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -5.426079 ymin: 5.684342e-14 xmax: 1.957316 ymax: 14.86258\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;             DHSID DHSCC DHSYEAR DHSCLUST CCFIPS ADM1FIPS ADM1FIPSNA ADM1SALBNA\n#&gt; 1  BF201000000001    BF    2010        1     UV     NULL       NULL       NULL\n#&gt; 2  BF201000000002    BF    2010        2     UV     NULL       NULL       NULL\n#&gt; 3  BF201000000003    BF    2010        3     UV     NULL       NULL       NULL\n#&gt; 4  BF201000000004    BF    2010        4     UV     NULL       NULL       NULL\n#&gt; 5  BF201000000005    BF    2010        5     UV     NULL       NULL       NULL\n#&gt; 6  BF201000000006    BF    2010        6     UV     NULL       NULL       NULL\n#&gt; 7  BF201000000007    BF    2010        7     UV     NULL       NULL       NULL\n#&gt; 8  BF201000000008    BF    2010        8     UV     NULL       NULL       NULL\n#&gt; 9  BF201000000009    BF    2010        9     UV     NULL       NULL       NULL\n#&gt; 10 BF201000000010    BF    2010       10     UV     NULL       NULL       NULL\n#&gt;    ADM1SALBCO ADM1DHS ADM1NAME DHSREGCO          DHSREGNA SOURCE URBAN_RURA\n#&gt; 1        NULL    9999     NULL       13         Sud-Ouest    GPS          R\n#&gt; 2        NULL    9999     NULL        2          Cascades    GPS          R\n#&gt; 3        NULL    9999     NULL       13         Sud-Ouest    GAZ          U\n#&gt; 4        NULL    9999     NULL       10              Nord    GPS          R\n#&gt; 5        NULL    9999     NULL        1 Boucle de Mouhoun    GPS          R\n#&gt; 6        NULL    9999     NULL        6      Centre-Ouest    GPS          R\n#&gt; 7        NULL    9999     NULL       12             Sahel    GPS          R\n#&gt; 8        NULL    9999     NULL        3            Centre    GPS          U\n#&gt; 9        NULL    9999     NULL        4        Centre-Est    GPS          U\n#&gt; 10       NULL    9999     NULL        5       Centre-Nord    GAZ          R\n#&gt;       LATNUM   LONGNUM ALT_GPS ALT_DEM DATUM                   geometry\n#&gt; 1  10.109415 -2.807555     269     269 WGS84 POINT (-2.807555 10.10942)\n#&gt; 2  10.388513 -3.907798     367     362 WGS84 POINT (-3.907798 10.38851)\n#&gt; 3   9.882864 -2.925703    9999     308 WGS84 POINT (-2.925703 9.882864)\n#&gt; 4  13.573418 -2.163120     323     323 WGS84  POINT (-2.16312 13.57342)\n#&gt; 5  12.453299 -3.461899     301     298 WGS84  POINT (-3.461899 12.4533)\n#&gt; 6  12.045308 -2.083828     338     325 WGS84 POINT (-2.083828 12.04531)\n#&gt; 7  14.354198 -0.672096     328     328 WGS84  POINT (-0.672096 14.3542)\n#&gt; 8  12.311034 -1.562071     322     324 WGS84 POINT (-1.562071 12.31103)\n#&gt; 9  11.780763 -0.363904     317     304 WGS84 POINT (-0.363904 11.78076)\n#&gt; 10 13.225114 -1.337994    9999     343 WGS84 POINT (-1.337994 13.22511)\n\nEach feature corresponds to one cluster location for which we have GPS coordinates, and each field represents a variable measured for each cluster. At the end of the output, you’ll also notice the aforementioned geometry column that contains the latitude and longitude for each displaced cluster location.\nSome clusters contain unverified coordinates and have been assigned a location of (0, 0). Since we have no way of linking these clusters to environmental data, we will remove them for this analysis using dplyr’s filter() function:\n\n# Remove empty geographies\nbf_gps &lt;- bf_gps |&gt; \n  filter(LATNUM != 0, LONGNUM != 0)\n\nVisualizing spatial data\nIt’s always worth double-checking that spatial data are being processed as expected, and this is often most easily done visually. We’ll use the ggspatial package to visualize our spatial data. This package is a convenient extension of the popular ggplot2 package.\n\n\n\n   © RStudio, Inc. (MIT) \nAs with ggplot2, ggspatial allows us to think of our plot in layers. The primary difference is that ggspatial’s layer_spatial() automatically maps the plot’s x and y dimensions to the geographic coordinates in the data.\n\n\n\n\n\n\nggplot2 and Themes\n\n\n\nThis post isn’t intended to be an introduction to ggplot2, so don’t worry if some of the plot code is unfamiliar to you—you should still be able to follow along with the other content in the post.\nAlso, we’ve modified some of the default theme elements for use in our plots throughout this post. We won’t cover all the details here, but note that your plots will likely look a bit different if you’re following along. For more about themes, see the associated documentation.\n\n\nTo add some context to our map, we’ll load a shapefile containing the Burkina Faso administrative borders. We’ll use the integrated geographies provided by IPUMS, which can be downloaded by clicking the shapefile link under the Burkina Faso section of this table. We’ve placed this shapefile alongside our DHS coordinate data in our data/gps directory, and can load it with st_read(), as we did before:\n\n# Load administrative boundary shapefile\nbf_borders &lt;- st_read(\n  \"data/gps/geo_bf2003_2010/geo_bf2003_2010.shp\",\n  quiet = TRUE\n)\n\nNow, we can plot the cluster locations (stored in bf_gps) along with the Burkina Faso administrative boundaries (stored in bf_borders):\n\nlibrary(ggplot2)\nlibrary(ggspatial)\n\n# Create map with cluster locations and BF boundaries \nggplot() +\n  layer_spatial(bf_borders, fill = NA) +\n  layer_spatial(bf_gps, size = 2, alpha = 0.4) +\n  labs(\n    title = \"Approximate DHS Cluster Locations\", \n    subtitle = \"Burkina Faso: 2010\",\n    caption = \"Source: DHS Program\"\n  ) +\n  annotation_scale(\n    aes(style = \"ticks\", location = \"br\"), \n    text_col = \"#999999\",\n    line_col = \"#999999\"\n  )\n\n\n\n\n\n\n\nSo far, everything seems to be working as expected—all the cluster points fall within the national borders, and there are noticeably more points in known urban areas, like the capital region of Ouagadougou. We should be safe to continue and load our precipitation data."
  },
  {
    "objectID": "posts/2024-02-04-dhs-chirps/index.html#chirps-precipitation-data",
    "href": "posts/2024-02-04-dhs-chirps/index.html#chirps-precipitation-data",
    "title": "Attaching CHIRPS Precipitation Data to DHS Surveys",
    "section": "CHIRPS precipitation data",
    "text": "CHIRPS precipitation data\nFor this post, we will use precipitation data from CHIRPS, a quasi-global gridded rainfall time-series with data from 1981 to the near-present.5 CHIRPS is frequently used in health, agricultural, and hydrological research because of its relatively high spatial and temporal resolution, and validation studies have shown it to perform better than other leading precipitation models across several metrics.6,7\nImportantly, the CHIRPS data are provided as raster data, not vector data. Instead of representing precipitation with a set of polygons or points (as with vector data), raster data represent geographic features in a grid, where each cell in the grid is associated with a particular value. In our case, each cell is associated with a single daily precipitation value (in millimeters).\n\n\nComparison of vector and raster data models4\n\nsf doesn’t provide support for raster data—instead, we’ll turn to the terra package.\nRaster data\nterra has rapidly become the go-to R package for working with raster data, and it is set to supersede the raster package, which was formerly used for raster operations.\n\n\n\n   © Robert J. Hijmans et al. (GPL &gt;=3) \nIn most cases, terra provides much faster processing than does the raster package. The magic behind terra is that it avoids reading many raster images into R at once. Instead, it reads metadata about each image—information about its spatial extent, coordinate reference system, pixel count, and so on.\n\n\n\n\n\n\nraster Package Retirement\n\n\n\nAt the time of writing, the raster package is still available on CRAN, but it will be retired soon. You may see other resources referencing the raster package, but we suggest relying only on terra to ensure that your code is robust to the upcoming retirement.\n\n\nInstalling terra\nYou’ll need the same operating system dependencies required for sf to use terra to its full potential. If you’ve already got those set up for sf, it should be easy to install terra with install.packages(\"terra\"). If not, follow these instructions to set up the package.\nLoading CHIRPS data\nThe complete CHIRPS precipitation data series can be downloaded directly from the UCSB Climate Hazards Center. However, because storing global data can require significant space, most users will likely want to download data for a specific area of interest.\nThere are two primary ways to go about downloading CHIRPS data for a particular area:\n\nSelect data interactively through the CHIRPS API provider: ClimateSERV. ClimateSERV hosts a graphical user interface (GUI) that allows you to select an area of interest on a map.\nAccess data through the CHIRPS API using the API client tools provided by the chirps package.\n\nThe first option has the advantage of being visual and intuitive. However, if you need to update your data for a new area or time range, you’ll have to go through the manual download process again.\nIn contrast, the second option prioritizes reproducibility and adaptability: updating the data used in your analysis is a matter of adjusting just a few lines of code. However, your R session will be occupied while downloading data, which can take a fair amount of time for long time-series.\nOption 1: ClimateSERV\nFirst, navigate to the ClimateSERV Map. From there, open the Statistical Query toolbar on the top of the left sidebar and click Select. Click Country under the Select features by dropdown. Then, click on the country of interest—in this case, Burkina Faso (in West Africa).\n\n\n\n\n\n\nWarning\n\n\n\nThe ClimateSERV interface may not work properly on all web browsers (e.g. Firefox). If you have difficulty, try opening the interface in a different browser.\n\n\n\n\n\n\n\n\n\n\nOnce you’ve indicated the country of interest, change the type of request to Download Raw Data and the download format to TIF. Finally, adjust the date range to start on 01/01/2001 and end on 12/31/2010. This will give us a 10-year range running up to the survey year, allowing us to calculate a long-run average.\nFinally, click Submit Query to download the daily rainfall totals. Note that downloading this much data may take a fair amount of time!\nOnce your request has been processed, you’ll receive a compressed (.zip) folder containing one TIF image for each day in the time span: that’s 3652 files containing many megabytes of raster data. We’ve placed the .zip file in the data directory and renamed it chirps.zip. You can unzip the file in R with unzip():\n\n# Unzip and place individual .tif files in a new `data/chirps` directory\nchirps_files &lt;- unzip(\"data/chirps.zip\", exdir = \"data/chirps\")\n\nOr, if you prefer to unzip the file manually, you can do so and then list the individual raster files with list.files():\n\n# Create list of paths to all individual raster files\nchirps_files &lt;- list.files(\"data/chirps\", full.names = TRUE)\n\nWe can load raster files with the rast() function from terra. When providing multiple files, terra will stack them so each input file becomes a single layer in a larger raster stack:\n\nlibrary(terra)\n\n# Load set of .tif files into into a single raster stack\nbf_precip &lt;- rast(chirps_files)\n\nOption 2: The chirps package\nWe can use the get_chirps() function from the chirps package to access CHIRPS data via the CHIRPS API. Since we don’t have a map where we can select our region of interest, we’ll have to provide a pre-loaded region representing the area for which we’d like data.\nWe can use the bf_borders object we created earlier to get data for the Burkina Faso region. We’ll use vect() to convert it to a SpatVector from terra (get_chirps() currently has more robust support for these objects). We’ll also input our desired date range for which to obtain data:\n\n\nThe SpatVector is the main object terra uses to represent vector data. We’ve already shown how to use sf to handle vector data, but terra also provides support for this data model. In general, we find that sf’s vector objects are a little more intuitive, but there are some cases where using terra may make certain operations easier or faster.\n\n# Load the chirps package\nlibrary(chirps)\n\n# Get CHIRPS data from 2001-2010 for Burkina Faso \nbf_precip &lt;- get_chirps(\n  vect(bf_borders),\n  dates = c(\"2001-01-01\",\"2010-12-31\"),\n  server = \"CHC\" # Recommended when obtaining data for multiple dates and/or locations\n)\n\nget_chirps() obtains data for a rectangular region around the country. For consistency with the results you would get from ClimateSERV (which only downloads data within the country borders), we’ll use terra’s mask() function to remove data from outside the Burkina Faso borders:\n\nbf_precip &lt;- mask(bf_precip, bf_borders, touches = FALSE)\n\n\n\n\n\n\n\nClimateSERV vs. chirps\n\n\n\nThere may be some trivial discrepancies between the data obtained via ClimateSERV and those obtained via the chirps package. When creating this post, we used data obtained via ClimateSERV.\nIf you instead obtained data from chirps, your values may differ slightly from those we present below. These differences shouldn’t meaningfully affect any of the operations we demonstrate.\n\n\n\nSpatRaster objects\nRegardless of the method you chose to access the CHIRPS data, you should now have a SpatRaster object from terra containing the raster stack of precipitation data covering the entirety of Burkina Faso from 2001 to 2010:\n\nbf_precip\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 115, 159, 3652  (nrow, ncol, nlyr)\n#&gt; resolution  : 0.05, 0.05  (x, y)\n#&gt; extent      : -5.549997, 2.400003, 9.349999, 15.1  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : lon/lat WGS 84 (EPSG:4326) \n#&gt; sources     : 20010101.tif  \n#&gt;               20010102.tif  \n#&gt;               20010103.tif  \n#&gt;               ... and 3649 more source(s)\n#&gt; names       : 20010101, 20010102, 20010103, 20010104, 20010105, 20010106, ...\n\nAs you can see, this raster layer contains 115 rows and 159 columns of pixels. The value in each pixel represents the rainfall (in millimeters) for an area 0.05 degrees longitude by 0.05 degrees latitude (shown in the resolution field).\nEach of the 3652 layers in the SpatRaster represents the CHIRPS precipitation values for a single day of the 10-year period between 2001 and 2010.\nTo better understand this structure, we can visualize the rainfall patterns for one of these days. We’ll first need to select an individual layer from the raster stack. We can index layers by name or layer position using [[ notation:\n\n# Select a single layer\n# (Layer names will vary depending on how you obtained your CHIRPS data)\nprecip_day &lt;- bf_precip[[\"20010719\"]]\n\nOnce we’ve selected a layer, we can use layer_spatial() to plot it, just as we did for vector objects.\n\nShow plot code# Create map of rainfall for single day\nggplot() +\n  layer_spatial(\n    precip_day, \n    alpha = if_else(values(precip_day) == 0, 0, 0.8), \n    na.rm = TRUE\n  ) +\n  layer_spatial(bf_borders, fill = NA, color = \"#888888\") +\n  layer_spatial(bf_gps,  fill = NA, size = 2, alpha = 0.4) +\n  labs(\n    title = \"Burkina Faso Rainfall: July 19, 2001\",\n    subtitle = \"CHIRPS precipitation data with DHS cluster locations\",\n    fill = \"Rainfall total (mm)\",\n    caption = \"Source: DHS Program and Climate Hazards Center InfraRed Precipitation with Station (CHIRPS)\"\n  ) +\n  annotation_scale(\n    aes(style = \"ticks\", location = \"br\"), \n    text_col = \"#999999\",\n    line_col = \"#999999\"\n  ) +\n  scale_fill_gradient(low = \"white\", high = \"#00263A\", na.value = NA) +\n  guides(\n    fill = guide_colorbar(\n      title.position = \"top\",\n      title.hjust = 0.5,\n      label.hjust = 0.5,\n      barwidth = 15,\n      barheight = 0.5,\n      ticks.colour = \"white\",\n      frame.colour = \"#999999\"\n    )\n  )\n\n\n\n\n\n\n\nIt can be unwieldy to manage many layers of raster data. In the next section, we’ll introduce methods for simplifying these data across both time and space so they can be more easily attached to our DHS survey."
  },
  {
    "objectID": "posts/2024-02-04-dhs-chirps/index.html#cluster-buffers",
    "href": "posts/2024-02-04-dhs-chirps/index.html#cluster-buffers",
    "title": "Attaching CHIRPS Precipitation Data to DHS Surveys",
    "section": "Cluster buffers",
    "text": "Cluster buffers\nWe might think it logical to extract the mean precipitation values at each cluster’s point location. However, recall that our motivating question centered around the idea that precipitation influences health by way of impacting local crop yields. The farms that serve the population of a given cluster won’t necessarily be situated right at the recorded cluster location. Furthermore, each farm is probably impacted by the precipitation patterns in its surrounding area, not only those that occur at its exact location.\nWith this in mind, it makes sense to generate a summary metric of the precipitation in the general area of each cluster, rather than at the cluster point locations. We can accomplish this by creating buffer zones around each cluster coordinate.\nWe can use st_buffer() to create an appropriately sized buffer zone around the displaced GPS coordinates for each cluster. However, sf’s geometrical operations (powered by GEOS) assume that the input data are in meters, and our data are currently in degrees.\nTherefore, we first need to project our GPS coordinates into a new coordinate reference system, or CRS. We will use the UTM Coordinate System Zone 30N for our projection, which provides limited distortion for Burkina Faso. The EPSG code for this UTM zone is 32630, which we can provide to st_transform() to project our data:\n\n\nMap projections constitute an entire topic on their own. To learn more about projected coordinate systems, there are countless resources online, like this treatment from ESRI\n\n# Project cluster locations to the UTM 30N reference system\nbf_gps &lt;- st_transform(bf_gps, crs = 32630)\n\nWe can use st_geometry() to see a summary of our sf object’s geometry. Note that the Projected CRS now shows UTM zone 30N, and that our data are now stored in meters, rather than degrees:\n\nst_geometry(bf_gps)\n#&gt; Geometry set for 541 features \n#&gt; Geometry type: POINT\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 234659.3 ymin: 1092462 xmax: 1039190 ymax: 1645174\n#&gt; Projected CRS: WGS 84 / UTM zone 30N\n#&gt; First 5 geometries:\n#&gt; POINT (521084.1 1117516)\n#&gt; POINT (400626 1148510)\n#&gt; POINT (508145.5 1092462)\n#&gt; POINT (590542.4 1500704)\n#&gt; POINT (449803.2 1376723)\n\n\n\nIf you need to check your work, you can always access the current CRS of your data with st_crs().\nNow that we’re working in meters, we can buffer our points using st_buffer(). The appropriate buffer distance will depend on your specific research question of interest. For this demonstration, we’ll create a 10-kilometer (10,000 meter) buffer by setting dist = 10000:\n\nbf_gps &lt;- st_buffer(bf_gps, dist = 10000)\n\nWe see that the geometry column now describes POLYGON geometries rather than POINT geometries. Each polygon is defined by a series of points that form the circumference of the buffer zone.\n\nst_geometry(bf_gps)\n#&gt; Geometry set for 541 features \n#&gt; Geometry type: POLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: 224659.3 ymin: 1082462 xmax: 1049190 ymax: 1655174\n#&gt; Projected CRS: WGS 84 / UTM zone 30N\n#&gt; First 5 geometries:\n#&gt; POLYGON ((531084.1 1117516, 531070.3 1116993, 5...\n#&gt; POLYGON ((410626 1148510, 410612.3 1147987, 410...\n#&gt; POLYGON ((518145.5 1092462, 518131.8 1091939, 5...\n#&gt; POLYGON ((600542.4 1500704, 600528.7 1500181, 6...\n#&gt; POLYGON ((459803.2 1376723, 459789.5 1376200, 4...\n\nWe’re finished measuring distance in meters, so we’ll again use st_transform() to revert back to degrees of latitude and longitude (EPSG 4326) for consistency with our other maps.\n\nbf_gps &lt;- st_transform(bf_gps, crs = 4326)\n\n\nShow plot codeggplot() + \n  layer_spatial(bf_borders, fill = NA) +\n  layer_spatial(bf_gps, fill = \"black\", alpha = 0.2) +\n  labs(\n    title = \"Buffered DHS Cluster Locations\",\n    subtitle = \"Burkina Faso: 2010\",\n    caption = \"Source: DHS Program\"\n  ) +\n  annotation_scale(\n    aes(style = \"ticks\", location = \"br\"), \n    text_col = \"#999999\",\n    line_col = \"#999999\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nHandling cluster displacement\n\n\n\nPreviously, we discussed the fact that the cluster coordinates provided by The DHS Program are displaced from their true locations. While we don’t need to address this for our precipitation data, there may be other cases where it is useful to obtain a more precise location for each cluster (for instance, if working with road networks or other fine-grained data).\nIn these cases, you can certainly buffer points conditionally on other values in the data by providing a conditional statement to the buffer dist argument. For instance, to buffer urban clusters (URBAN_RURA == \"U\") by 2000 meters and other clusters by 5000 meters, use an if_else() statement:\n\nst_buffer(\n  bf_gps, \n  dist = if_else(bf_gps$URBAN_RURA == \"U\", 2000, 5000)\n)"
  },
  {
    "objectID": "posts/2024-02-04-dhs-chirps/index.html#aggregating-rainfall-within-cluster-regions",
    "href": "posts/2024-02-04-dhs-chirps/index.html#aggregating-rainfall-within-cluster-regions",
    "title": "Attaching CHIRPS Precipitation Data to DHS Surveys",
    "section": "Aggregating rainfall within cluster regions",
    "text": "Aggregating rainfall within cluster regions\nNow that we have buffered cluster regions, we can focus on combining our two data sources. Let’s zoom in on a single cluster as an example. We’ll use the cluster with DHSCLUST number 160:\n\nclust &lt;- bf_gps |&gt; \n  filter(DHSCLUST == 160)\n\nTo simplify this example, we’ll use terra’s crop() to restrict our raster to the cells surrounding this cluster:\n\nprecip_clust &lt;- crop(bf_precip_mean, clust, snap = \"out\")\n\n\nShow plot codeggplot() + \n  layer_spatial(precip_clust, alpha = 0.8) + \n  layer_spatial(clust, alpha = 0, linewidth = 0.5, color = \"black\") +\n  labs(\n    title = \"Average Rainfall: 2001-2010\",\n    subtitle = \"Single DHS cluster\",\n    fill = \"10-year average rainfall (mm/day)\",\n    caption = \"Source: DHS Program and Climate Hazards Center InfraRed Precipitation with Station (CHIRPS)\"\n  ) +\n  scale_fill_gradient(\n    low = \"#FAEFD1\", \n    high = \"#00263A\", \n    na.value = NA, \n    limits = c(2.3, 2.5)\n  ) +\n  guides(\n    fill = guide_colorbar(\n      title.position = \"top\",\n      title.hjust = 0.5,\n      label.hjust = 0.5,\n      barwidth = 15,\n      barheight = 0.5,\n      ticks.colour = \"white\",\n      frame.colour = \"#999999\"\n    )\n  )\n\n\n\n\n\n\n\n\n\nFor demonstration purposes, we’ve used different limits for the color scale in this plot and the next. In general, we’d want to ensure that the colors in this plot map to the same values used in other plots with the same color scheme.\nWe see a range of rainfall totals across the 20 pixels in this area. How can we summarize the information contained in these individual pixels into a single estimate of the rainfall for this buffered cluster region?\nThe most straightforward approach might be to take the mean of all the pixel values that overlap our buffer region. First, we need to obtain the values of the overlapping raster cells. We can use terra’s extract() to obtain the raster cell values from the region defined by an overlapping vector data source (in this case, our example cluster, clust):\n\nextract(bf_precip_mean, clust)\n#&gt;    ID     mean\n#&gt; 1   1 2.337887\n#&gt; 2   1 2.329431\n#&gt; 3   1 2.344792\n#&gt; 4   1 2.317271\n#&gt; 5   1 2.343546\n#&gt; 6   1 2.329051\n#&gt; 7   1 2.381871\n#&gt; 8   1 2.367312\n#&gt; 9   1 2.395538\n#&gt; 10  1 2.395361\n#&gt; 11  1 2.402505\n#&gt; 12  1 2.415130\n\nNote that this provides mean daily precipitation values for 12 different cells. By default, extract() will only extract values from the cells whose center point lies within the overlaid polygon:\n\nShow plot code# New SpatRaster with same extent as bf_precip_mean, but with empty values\next_cells &lt;- rast(bf_precip_mean, vals = NA)\n\n# ID cell locations for each cell that is extracted\ncell_idx &lt;- extract(ext_cells, clust, cells = TRUE)$cell\n\next_cells[cell_idx] &lt;- bf_precip_mean[cell_idx]\n\nggplot() + \n  layer_spatial(\n    crop(ext_cells, clust, snap = \"out\"), \n    alpha = 0.8, \n    na.rm = TRUE\n  ) +\n  layer_spatial(clust, alpha = 0, linewidth = 0.5, color = \"black\") +\n  labs(\n    title = \"Average Rainfall: 2001-2010\",\n    subtitle = \"Single DHS cluster\",\n    fill = \"10-year average rainfall (mm/day)\",\n    caption = \"Source: DHS Program and Climate Hazards Center InfraRed Precipitation with Station (CHIRPS)\"\n  ) +\n  scale_fill_gradient(\n    low = \"#FAEFD1\", \n    high = \"#00263A\", \n    na.value = NA, \n    limits = c(2.3, 2.5)\n  ) +\n  guides(\n    fill = guide_colorbar(\n      title.position = \"top\",\n      title.hjust = 0.5,\n      label.hjust = 0.5,\n      barwidth = 15,\n      barheight = 0.5,\n      ticks.colour = \"white\",\n      frame.colour = \"#999999\"\n    )\n  )\n\n\n\n\n\n\n\nTo instead include all cells that intersect the polygon, set touches = TRUE:\n\nclust_precip &lt;- extract(bf_precip_mean, clust, touches = TRUE)\n\nclust_precip\n#&gt;    ID     mean\n#&gt; 1   1 2.350189\n#&gt; 2   1 2.319925\n#&gt; 3   1 2.385132\n#&gt; 4   1 2.337887\n#&gt; 5   1 2.329431\n#&gt; 6   1 2.328763\n#&gt; 7   1 2.344792\n#&gt; 8   1 2.317271\n#&gt; 9   1 2.343546\n#&gt; 10  1 2.329051\n#&gt; 11  1 2.381871\n#&gt; 12  1 2.367312\n#&gt; 13  1 2.395538\n#&gt; 14  1 2.395361\n#&gt; 15  1 2.393321\n#&gt; 16  1 2.402505\n#&gt; 17  1 2.415130\n#&gt; 18  1 2.395817\n\nThis operation provides the mean daily precipitation values for each of the 18 cells that intersect our cluster region. However, some cells cover a much larger portion of the cluster region than others. To account for the heterogeneity in size, we can set weights = TRUE to include a weight column, which records the proportion of each cell that is covered by the polygon:\n\n\nweights = TRUE automatically includes all intersected cells, but those with negligible weights will be removed.\n\nclust_precip &lt;- extract(bf_precip_mean, clust, weights = TRUE)\n\nclust_precip\n#&gt;    ID     mean weight\n#&gt; 1   1 2.385132   0.20\n#&gt; 2   1 2.337887   0.90\n#&gt; 3   1 2.329431   0.94\n#&gt; 4   1 2.328763   0.33\n#&gt; 5   1 2.344792   0.70\n#&gt; 6   1 2.317271   1.00\n#&gt; 7   1 2.343546   1.00\n#&gt; 8   1 2.329051   0.86\n#&gt; 9   1 2.381871   0.57\n#&gt; 10  1 2.367312   1.00\n#&gt; 11  1 2.395538   1.00\n#&gt; 12  1 2.395361   0.74\n#&gt; 13  1 2.393321   0.03\n#&gt; 14  1 2.402505   0.47\n#&gt; 15  1 2.415130   0.53\n#&gt; 16  1 2.395817   0.09\n\nWe can then provide the weights to the weighted.mean() function to calculate a weighted mean that is shifted toward the cell values that form a larger proportion of the polygon area.\n\nweighted.mean(clust_precip$mean, clust_precip$weight)\n#&gt; [1] 2.358508\n\nBecause this kind of workflow is so common, terra provides a quicker shorthand in extract(). You can use the fun argument to specify an aggregation function at the same time that you extract the raster cell values:\n\n# Extract area-weighted average for all cells covered by `clust`\nextract(\n  bf_precip_mean,\n  clust,\n  fun = \"mean\", # Average all extracted values\n  weights = TRUE # Use area weights\n)\n#&gt;   ID     mean\n#&gt; 1  1 2.358508\n\nThe 2.358508 value represents the area-weighted mean of the 10-year mean precipitation values (in millimeters per day) within the given cluster region.\nScaling up for all clusters\nTo aggregate the rainfall data for each DHS cluster in the sample, we simply scale up. We again use extract(), but we provide our raster of precipitation values for the entire country and the polygons for all of our buffered clusters.\n\n# Average the mean CHIRPS values within each DHS cluster\nclust_means &lt;- extract(\n  bf_precip_mean,\n  bf_gps, # All clusters included\n  fun = \"mean\",\n  weights = TRUE,\n  na.rm = TRUE, # Ignore missing CHIRPS values\n  bind = TRUE # Recombine with original `bf_gps` data\n)\n\nBy setting bind = TRUE, we can automatically recombine the extracted means with the other cluster data in bf_gps.\nWe also set na.rm = TRUE to ensure we don’t get missing values for clusters whose regions expand beyond the country borders (where we haven’t downloaded any CHIRPS data). This decision may be reasonable if our interest is in rainfall over local crop-producing regions, and we don’t believe that clusters in border regions obtain substantial inputs from farms outside of the country. (If we wanted to include the rainfall outside of the country borders, we would simply need to expand our bounding box when downloading our CHIRPS data.)\nFinally, we’ll convert our cluster means back to an sf object. Notice that there now exists a mean column that stores the weighted mean values for each cluster:\n\n# Convert to sf object\nclust_means &lt;- st_as_sf(clust_means)\n\nclust_means |&gt; \n  select(DHSID, mean, geometry)\n#&gt; Simple feature collection with 541 features and 2 fields\n#&gt; Geometry type: POLYGON\n#&gt; Dimension:     XY\n#&gt; Bounding box:  xmin: -5.517451 ymin: 9.792417 xmax: 2.049008 ymax: 14.95288\n#&gt; Geodetic CRS:  WGS 84\n#&gt; First 10 features:\n#&gt;             DHSID     mean                       geometry\n#&gt; 1  BF201000000001 2.758146 POLYGON ((-2.71628 10.10935...\n#&gt; 2  BF201000000002 2.782180 POLYGON ((-3.816453 10.3887...\n#&gt; 3  BF201000000003 3.004422 POLYGON ((-2.834491 9.88283...\n#&gt; 4  BF201000000004 1.678181 POLYGON ((-2.070699 13.5730...\n#&gt; 5  BF201000000005 2.129466 POLYGON ((-3.369883 12.4534...\n#&gt; 6  BF201000000006 2.203529 POLYGON ((-1.991964 12.0449...\n#&gt; 7  BF201000000007 1.113443 POLYGON ((-0.579432 14.3532...\n#&gt; 8  BF201000000008 2.110246 POLYGON ((-1.470133 12.3105...\n#&gt; 9  BF201000000009 2.281224 POLYGON ((-0.2722169 11.779...\n#&gt; 10 BF201000000010 1.722371 POLYGON ((-1.245736 13.2245...\n\nNow that we have aggregated rainfall across all clusters, we can plot the average rainfall for each of the 10-kilometer buffered cluster regions. Each cluster region is associated with a single 10-year average rainfall value.\n\nShow plot codeggplot() + \n  layer_spatial(bf_borders, fill = NA) +\n  layer_spatial(clust_means, aes(fill = mean), alpha = 0.8) +\n  labs(\n    title = \"Average Rainfall within Clusters: 2001-2010\",\n    subtitle = \"Burkina Faso: 2010 Clusters\",\n    fill = \"10-year average rainfall (mm/day)\",\n    caption = \"Source: DHS Program and Climate Hazards Center InfraRed Precipitation with Station (CHIRPS)\"\n  ) +\n  annotation_scale(\n    aes(style = \"ticks\", location = \"br\"), \n    text_col = \"#999999\",\n    line_col = \"#999999\"\n  ) +\n  guides( # Override some of our theme_dhs_extended() defaults for this plot\n    fill = guide_colorbar(       \n      title.position = \"top\",\n      title.hjust = 0.5,\n      label.hjust = 0.5,\n      barwidth = 15,\n      barheight = 0.5,\n      ticks.colour = NA,\n      frame.colour = \"#999999\"\n    )\n  ) +\n  scale_fill_steps(low = \"#FAEFD1\", high = \"#00263A\", n.breaks = 4)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Latest Posts",
    "section": "",
    "text": "Attaching CHIRPS Precipitation Data to DHS Surveys\n\n\n\n\n\n\n\nCHIRPS\n\n\nPrecipitation\n\n\nClimate\n\n\nAgriculture\n\n\nterra\n\n\nsf\n\n\nggspatial\n\n\nR\n\n\n\n\nRemotely sensed precipitation data can provide important context for understanding the health outcomes reported in the DHS\n\n\n\n\n\n\nFeb 4, 2024\n\n\nFinn Roberts, Matt Gunther\n\n\n\n\n\n\n  \n\n\n\n\nDeveloping Robust Conceptual Models in Climate Change and Health Research\n\n\n\n\n\n\n\nClimate\n\n\nMethodology\n\n\nResearch concepts\n\n\n\n\nIntroducing the theoretical foundations for effective research on climate change and health\n\n\n\n\n\n\nFeb 3, 2024\n\n\nElizabeth Heger Boyle, Kathryn Grace, Audrey Dorélien, Devon Kristiansen\n\n\n\n\n\n\n  \n\n\n\n\nObtaining Data from IPUMS DHS\n\n\n\n\n\n\n\nTips\n\n\nImporting data\n\n\nR\n\n\n\n\nIdentify and download data from the IPUMS DHS website and load it into R\n\n\n\n\n\n\nFeb 2, 2024\n\n\nFinn Roberts, Matt Gunther\n\n\n\n\n\n\n  \n\n\n\n\nAn Introduction to R\n\n\n\n\n\n\n\nTips\n\n\nR\n\n\n\n\nGetting started with R and RStudio\n\n\n\n\n\n\nFeb 1, 2024\n\n\nFinn Roberts, Matt Gunther\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About this Blog",
    "section": "",
    "text": "IPUMS DHS data provide a critical resource to help illuminate the relationship between climate change and population health. To support such research, the IPUMS Global Health team received a 2023 supplemental grant from the Eunice Kennedy Shriver National Institute of Child Health and Human Development, or NICHD (3R01HD069471-12S1).\nThis blog is designed to be a resource for researchers who are familiar with population health survey data but new to research using spatial data sources. The blog will introduce spatial data concepts and demonstrate basic spatial data processing techniques in R.\nAdditionally, the supplemental grant supports:\n\nthe integration and dissemination of DHS malaria monitoring data (MIS surveys) in IPUMS DHS.\nthe dissemination of displaced GPS coordinates for DHS primary sampling units and the addition of new contextual variables to the IPUMS data extract system.\n\nThese three elements will make it easier to add environmental context to research using IPUMS DHS surveys and will provide additional data relevant to disease vector transmission. Combined, they will enhance researchers’ ability to use IPUMS DHS data to understand the impacts of climate change on health.\n\n\nThis blog is developed in collaboration with the Climate Hazards Center at the University of California, Santa Barbara and is supported by USAID Cooperative Agreement 72DFFP19CA00001.\nThe IPUMS research team also receives support as members of the Minnesota Population Center through a grant from the NICHD Population Research Infrastructure Program (P2C HD041023)."
  },
  {
    "objectID": "about.html#supporting-climate-and-health-research",
    "href": "about.html#supporting-climate-and-health-research",
    "title": "About this Blog",
    "section": "",
    "text": "IPUMS DHS data provide a critical resource to help illuminate the relationship between climate change and population health. To support such research, the IPUMS Global Health team received a 2023 supplemental grant from the Eunice Kennedy Shriver National Institute of Child Health and Human Development, or NICHD (3R01HD069471-12S1).\nThis blog is designed to be a resource for researchers who are familiar with population health survey data but new to research using spatial data sources. The blog will introduce spatial data concepts and demonstrate basic spatial data processing techniques in R.\nAdditionally, the supplemental grant supports:\n\nthe integration and dissemination of DHS malaria monitoring data (MIS surveys) in IPUMS DHS.\nthe dissemination of displaced GPS coordinates for DHS primary sampling units and the addition of new contextual variables to the IPUMS data extract system.\n\nThese three elements will make it easier to add environmental context to research using IPUMS DHS surveys and will provide additional data relevant to disease vector transmission. Combined, they will enhance researchers’ ability to use IPUMS DHS data to understand the impacts of climate change on health.\n\n\nThis blog is developed in collaboration with the Climate Hazards Center at the University of California, Santa Barbara and is supported by USAID Cooperative Agreement 72DFFP19CA00001.\nThe IPUMS research team also receives support as members of the Minnesota Population Center through a grant from the NICHD Population Research Infrastructure Program (P2C HD041023)."
  },
  {
    "objectID": "about.html#what-is-ipums-dhs",
    "href": "about.html#what-is-ipums-dhs",
    "title": "About this Blog",
    "section": "What is IPUMS DHS?",
    "text": "What is IPUMS DHS?\nIPUMS provides census and survey data from around the world integrated across time and space. IPUMS integration and documentation makes it easy to study change, conduct comparative research, merge information across data types, and analyze individuals within family and community context.\nIPUMS is comprised of several individual products, each with different data sources and content areas. IPUMS DHS is one of several IPUMS Global Health products—representative household surveys, primarily from low- and middle-income countries, that gather extensive information on health, family planning, living conditions, and more.\nIPUMS DHS specifically facilitates analysis of data provided by The Demographic and Health Surveys Program (DHS), which has been administered in low- and middle-income countries since the 1980s.\nIPUMS DHS harmonizes DHS variables over time and provides comprehensive cross-survey documentation to make it easier to find and understand DHS data.\nIPUMS DHS data are available free of charge, but users must register with The DHS Program to gain access. Registered DHS users can enter their DHS username and password to access data from IPUMS DHS. For more information about downloading IPUMS DHS data, see the associated post."
  },
  {
    "objectID": "about.html#how-to-cite",
    "href": "about.html#how-to-cite",
    "title": "About this Blog",
    "section": "How to cite",
    "text": "How to cite\nFor a comprehensive guide to citing IPUMS DHS, see the citation page on the IPUMS DHS website.\nTo cite an individual post on this blog, we suggest the following format:\n\nRoberts, F., & Gunther, M. (2024, Februrary 4). Attaching CHIRPS precipitation data to DHS surveys. IPUMS DHS Climate Change and Health Research Hub. https://tech.popdata.org/dhs-research-hub/posts/2024-02-04-dhs-chirps/index.html"
  },
  {
    "objectID": "about.html#getting-help",
    "href": "about.html#getting-help",
    "title": "About this Blog",
    "section": "Getting help",
    "text": "Getting help\nIPUMS users can find help on the IPUMS User Forum or by contacting IPUMS user support at ipums@umn.edu."
  },
  {
    "objectID": "about.html#related-work",
    "href": "about.html#related-work",
    "title": "About this Blog",
    "section": "Related work",
    "text": "Related work\nIPUMS Global Health also houses the IPUMS PMA Data Analysis Hub, a similar blog focused on working with IPUMS PMA data in R."
  }
]